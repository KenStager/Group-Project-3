{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.9/site-packages (3.7)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.9/site-packages (1.4.0)\n",
      "Requirement already satisfied: gensim in /opt/anaconda3/lib/python3.9/site-packages (4.1.2)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.9/site-packages (2.2.0)\n",
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.9/site-packages (4.40.1)\n",
      "Requirement already satisfied: textstat in /opt/anaconda3/lib/python3.9/site-packages (0.7.3)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.9/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.9/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.9/site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.9/site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in /opt/anaconda3/lib/python3.9/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.9/site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from scikit-learn) (3.3.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/anaconda3/lib/python3.9/site-packages (from gensim) (6.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.9/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.9/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.9/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.23.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.9/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: pyphen in /opt/anaconda3/lib/python3.9/site-packages (from textstat) (0.15.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk scikit-learn gensim pandas transformers textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/kenstager/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/opt/anaconda3/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary embedding shape: (1, 768)\n",
      "Blog embedding shape: (1, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary embedding shape: (1, 768)\n",
      "Blog embedding shape: (1, 768)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 133>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m summary_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummaries\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    132\u001b[0m blog_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWritten Blog Posts/3.5T Blog\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 133\u001b[0m results_df_sum_to_35 \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_files_and_calculate_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblog_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Display results\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28mprint\u001b[39m(results_df_sum_to_35)\n",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36mprocess_files_and_calculate_metrics\u001b[0;34m(summary_folder, blog_folder)\u001b[0m\n\u001b[1;32m    102\u001b[0m exact_match_ratio \u001b[38;5;241m=\u001b[39m calculate_exact_match_ratio(summary_text, blog_text)\n\u001b[1;32m    103\u001b[0m cosine_sim \u001b[38;5;241m=\u001b[39m calculate_cosine_similarity(summary_text, blog_text)\n\u001b[0;32m--> 104\u001b[0m topic_overlap \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_topic_overlap\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblog_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m key_phrase_overlap \u001b[38;5;241m=\u001b[39m calculate_key_phrase_overlap(summary_text, blog_text)\n\u001b[1;32m    106\u001b[0m semantic_similarity \u001b[38;5;241m=\u001b[39m calculate_semantic_similarity(summary_text, blog_text)\n",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36mcalculate_topic_overlap\u001b[0;34m(summary_text, blog_text)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_topic_overlap\u001b[39m(summary_text, blog_text):\n\u001b[1;32m     30\u001b[0m     documents \u001b[38;5;241m=\u001b[39m [summary_text, blog_text]\n\u001b[0;32m---> 31\u001b[0m     dictionary \u001b[38;5;241m=\u001b[39m corpora\u001b[38;5;241m.\u001b[39mDictionary([word_tokenize(doc) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents])\n\u001b[1;32m     32\u001b[0m     corpus \u001b[38;5;241m=\u001b[39m [dictionary\u001b[38;5;241m.\u001b[39mdoc2bow(word_tokenize(doc)) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m     33\u001b[0m     lda \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mLdaModel(corpus, num_topics\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, id2word\u001b[38;5;241m=\u001b[39mdictionary)\n",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_topic_overlap\u001b[39m(summary_text, blog_text):\n\u001b[1;32m     30\u001b[0m     documents \u001b[38;5;241m=\u001b[39m [summary_text, blog_text]\n\u001b[0;32m---> 31\u001b[0m     dictionary \u001b[38;5;241m=\u001b[39m corpora\u001b[38;5;241m.\u001b[39mDictionary([\u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents])\n\u001b[1;32m     32\u001b[0m     corpus \u001b[38;5;241m=\u001b[39m [dictionary\u001b[38;5;241m.\u001b[39mdoc2bow(word_tokenize(doc)) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m     33\u001b[0m     lda \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mLdaModel(corpus, num_topics\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, id2word\u001b[38;5;241m=\u001b[39mdictionary)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/nltk/tokenize/__init__.py:130\u001b[0m, in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03mReturn a tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03musing NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03m:type preserve_line: bool\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m sent_tokenize(text, language)\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    131\u001b[0m     token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[1;32m    132\u001b[0m ]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/nltk/tokenize/__init__.py:131\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03mReturn a tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03musing NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03m:type preserve_line: bool\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m sent_tokenize(text, language)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m--> 131\u001b[0m     token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_treebank_word_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m ]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/nltk/tokenize/destructive.py:182\u001b[0m, in \u001b[0;36mNLTKWordTokenizer.tokenize\u001b[0;34m(self, text, convert_parentheses, return_str)\u001b[0m\n\u001b[1;32m    179\u001b[0m     text \u001b[38;5;241m=\u001b[39m regexp\u001b[38;5;241m.\u001b[39msub(substitution, text)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m regexp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCONTRACTIONS2:\n\u001b[0;32m--> 182\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mregexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m1 \u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m2 \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m regexp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCONTRACTIONS3:\n\u001b[1;32m    184\u001b[0m     text \u001b[38;5;241m=\u001b[39m regexp\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m1 \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m2 \u001b[39m\u001b[38;5;124m\"\u001b[39m, text)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim import corpora, models\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import textstat\n",
    "import pandas as pd\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Function to calculate Exact Match Ratio\n",
    "def calculate_exact_match_ratio(summary_text, blog_text):\n",
    "    summary_words = set(word_tokenize(summary_text))\n",
    "    blog_words = set(word_tokenize(blog_text))\n",
    "    matches = summary_words.intersection(blog_words)\n",
    "    return len(matches) / len(summary_words)\n",
    "\n",
    "# Function to calculate Cosine Similarity\n",
    "def calculate_cosine_similarity(summary_text, blog_text):\n",
    "    vectorizer = TfidfVectorizer().fit_transform([summary_text, blog_text])\n",
    "    vectors = vectorizer.toarray()\n",
    "    return cosine_similarity(vectors)[0, 1]\n",
    "\n",
    "# Function for Topic Modeling\n",
    "def calculate_topic_overlap(summary_text, blog_text):\n",
    "    documents = [summary_text, blog_text]\n",
    "    dictionary = corpora.Dictionary([word_tokenize(doc) for doc in documents])\n",
    "    corpus = [dictionary.doc2bow(word_tokenize(doc)) for doc in documents]\n",
    "    lda = models.LdaModel(corpus, num_topics=5, id2word=dictionary)\n",
    "    topics_summary = lda.get_document_topics(corpus[0])\n",
    "    topics_blog = lda.get_document_topics(corpus[1])\n",
    "    return compute_topic_overlap(topics_summary, topics_blog)\n",
    "\n",
    "# Helper function to compute topic overlap\n",
    "def compute_topic_overlap(topics_summary, topics_blog):\n",
    "    summary_topics = {topic[0] for topic in topics_summary}\n",
    "    blog_topics = {topic[0] for topic in topics_blog}\n",
    "    overlap = summary_topics.intersection(blog_topics)\n",
    "    return len(overlap) / max(len(summary_topics), len(blog_topics))\n",
    "\n",
    "# Function to extract and compare Key Phrases\n",
    "def calculate_key_phrase_overlap(summary_text, blog_text):\n",
    "    summary_phrases = extract_key_phrases(summary_text)\n",
    "    blog_phrases = extract_key_phrases(blog_text)\n",
    "    matches = set(summary_phrases).intersection(set(blog_phrases))\n",
    "    return len(matches) / len(summary_phrases)\n",
    "\n",
    "# Helper function to extract key phrases (simple implementation)\n",
    "def extract_key_phrases(text):\n",
    "    words = word_tokenize(text)\n",
    "    return list(set(words))  # Simplified: using unique words as key phrases\n",
    "\n",
    "# Function for Semantic Similarity using BERT\n",
    "def calculate_semantic_similarity(summary_text, blog_text):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    def embed_text(text):\n",
    "        inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "        outputs = model(**inputs)\n",
    "        return outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "\n",
    "    summary_embedding = embed_text(summary_text)\n",
    "    blog_embedding = embed_text(blog_text)\n",
    "\n",
    "    print(f\"Summary embedding shape: {summary_embedding.shape}\")\n",
    "    print(f\"Blog embedding shape: {blog_embedding.shape}\")\n",
    "\n",
    "    if summary_embedding.shape[0] == 1 and blog_embedding.shape[0] == 1:\n",
    "        return cosine_similarity(summary_embedding, blog_embedding)[0, 0]\n",
    "    else:\n",
    "        return 0  # Return 0 similarity if embeddings are not as expected\n",
    "\n",
    "# Function to calculate Readability Scores using textstat\n",
    "def calculate_readability_scores(text):\n",
    "    return textstat.flesch_kincaid_grade(text)\n",
    "\n",
    "# Function to analyze Sentence Length and Structure\n",
    "def analyze_sentence_structure(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    lengths = [len(word_tokenize(sent)) for sent in sentences]\n",
    "    avg_length = sum(lengths) / len(sentences)\n",
    "    return avg_length, lengths\n",
    "\n",
    "# Main function to process files and calculate metrics\n",
    "def process_files_and_calculate_metrics(summary_folder, blog_folder):\n",
    "    results = []\n",
    "\n",
    "    summary_files = sorted(glob.glob(os.path.join(summary_folder, \"*.txt\")))\n",
    "    blog_files = sorted(glob.glob(os.path.join(blog_folder, \"*.txt\")))\n",
    "\n",
    "    for summary_file, blog_file in zip(summary_files, blog_files):\n",
    "        with open(summary_file, 'r') as sf:\n",
    "            summary_text = sf.read()\n",
    "        with open(blog_file, 'r') as bf:\n",
    "            blog_text = bf.read()\n",
    "\n",
    "        exact_match_ratio = calculate_exact_match_ratio(summary_text, blog_text)\n",
    "        cosine_sim = calculate_cosine_similarity(summary_text, blog_text)\n",
    "        topic_overlap = calculate_topic_overlap(summary_text, blog_text)\n",
    "        key_phrase_overlap = calculate_key_phrase_overlap(summary_text, blog_text)\n",
    "        semantic_similarity = calculate_semantic_similarity(summary_text, blog_text)\n",
    "        readability_summary = calculate_readability_scores(summary_text)\n",
    "        readability_blog = calculate_readability_scores(blog_text)\n",
    "        sentence_length_summary, _ = analyze_sentence_structure(summary_text)\n",
    "        sentence_length_blog, _ = analyze_sentence_structure(blog_text)\n",
    "\n",
    "        results.append({\n",
    "            \"summary_file\": os.path.basename(summary_file),\n",
    "            \"blog_file\": os.path.basename(blog_file),\n",
    "            \"exact_match_ratio\": exact_match_ratio,\n",
    "            \"cosine_similarity\": cosine_sim,\n",
    "            \"topic_overlap\": topic_overlap,\n",
    "            \"key_phrase_overlap\": key_phrase_overlap,\n",
    "            \"semantic_similarity\": semantic_similarity,\n",
    "            \"readability_summary\": readability_summary,\n",
    "            \"readability_blog\": readability_blog,\n",
    "            \"sentence_length_summary\": sentence_length_summary,\n",
    "            \"sentence_length_blog\": sentence_length_blog\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv('comparison_results.csv', index=False)\n",
    "    return df\n",
    "\n",
    "# Call main function with appropriate folder paths\n",
    "summary_folder = 'summaries'\n",
    "blog_folder = 'Written Blog Posts/3.5T Blog'\n",
    "results_df_sum_to_35 = process_files_and_calculate_metrics(summary_folder, blog_folder)\n",
    "\n",
    "# Display results\n",
    "print(results_df_sum_to_35)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_sum_to_35.to_csv('Individual Comparative CSVs/comparison_results_sum_to_3.5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim import corpora, models\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import textstat\n",
    "import pandas as pd\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Function to calculate Exact Match Ratio\n",
    "def calculate_exact_match_ratio(raw_text, blog_text):\n",
    "    raw_words = set(word_tokenize(raw_text))\n",
    "    blog_words = set(word_tokenize(blog_text))\n",
    "    matches = raw_words.intersection(blog_words)\n",
    "    return len(matches) / len(raw_words)\n",
    "\n",
    "# Function to calculate Cosine Similarity\n",
    "def calculate_cosine_similarity(raw_text, blog_text):\n",
    "    vectorizer = TfidfVectorizer().fit_transform([raw_text, blog_text])\n",
    "    vectors = vectorizer.toarray()\n",
    "    return cosine_similarity(vectors)[0, 1]\n",
    "\n",
    "# Function for Topic Modeling\n",
    "def calculate_topic_overlap(raw_text, blog_text):\n",
    "    documents = [raw_text, blog_text]\n",
    "    dictionary = corpora.Dictionary([word_tokenize(doc) for doc in documents])\n",
    "    corpus = [dictionary.doc2bow(word_tokenize(doc)) for doc in documents]\n",
    "    lda = models.LdaModel(corpus, num_topics=5, id2word=dictionary)\n",
    "    topics_raw = lda.get_document_topics(corpus[0])\n",
    "    topics_blog = lda.get_document_topics(corpus[1])\n",
    "    return compute_topic_overlap(topics_raw, topics_blog)\n",
    "\n",
    "# Helper function to compute topic overlap\n",
    "def compute_topic_overlap(topics_raw, topics_blog):\n",
    "    raw_topics = {topic[0] for topic in topics_raw}\n",
    "    blog_topics = {topic[0] for topic in topics_blog}\n",
    "    overlap = raw_topics.intersection(blog_topics)\n",
    "    return len(overlap) / max(len(raw_topics), len(blog_topics))\n",
    "\n",
    "# Function to extract and compare Key Phrases\n",
    "def calculate_key_phrase_overlap(raw_text, blog_text):\n",
    "    raw_phrases = extract_key_phrases(raw_text)\n",
    "    blog_phrases = extract_key_phrases(blog_text)\n",
    "    matches = set(raw_phrases).intersection(set(blog_phrases))\n",
    "    return len(matches) / len(raw_phrases)\n",
    "\n",
    "# Helper function to extract key phrases (simple implementation)\n",
    "def extract_key_phrases(text):\n",
    "    words = word_tokenize(text)\n",
    "    return list(set(words))  # Simplified: using unique words as key phrases\n",
    "\n",
    "# Function for Semantic Similarity using BERT\n",
    "def calculate_semantic_similarity(raw_text, blog_text):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    def embed_text(text):\n",
    "        inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "        outputs = model(**inputs)\n",
    "        return outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "\n",
    "    raw_embedding = embed_text(raw_text)\n",
    "    blog_embedding = embed_text(blog_text)\n",
    "\n",
    "    print(f\"Raw text embedding shape: {raw_embedding.shape}\")\n",
    "    print(f\"Blog embedding shape: {blog_embedding.shape}\")\n",
    "\n",
    "    if raw_embedding.shape[0] == 1 and blog_embedding.shape[0] == 1:\n",
    "        return cosine_similarity(raw_embedding, blog_embedding)[0, 0]\n",
    "    else:\n",
    "        return 0  # Return 0 similarity if embeddings are not as expected\n",
    "\n",
    "# Function to calculate Readability Scores using textstat\n",
    "def calculate_readability_scores(text):\n",
    "    return textstat.flesch_kincaid_grade(text)\n",
    "\n",
    "# Function to analyze Sentence Length and Structure\n",
    "def analyze_sentence_structure(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    lengths = [len(word_tokenize(sent)) for sent in sentences]\n",
    "    avg_length = sum(lengths) / len(sentences)\n",
    "    return avg_length, lengths\n",
    "\n",
    "# Main function to process files and calculate metrics\n",
    "def process_files_and_calculate_metrics(raw_folder, blog_folder, num_files):\n",
    "    results = []\n",
    "\n",
    "    raw_files = sorted(glob.glob(os.path.join(raw_folder, \"*.txt\")))\n",
    "    blog_files = sorted(glob.glob(os.path.join(blog_folder, \"*.txt\")))\n",
    "\n",
    "    for i in range(num_files):\n",
    "        raw_file = raw_files[i]\n",
    "        blog_file = blog_files[i]\n",
    "\n",
    "        with open(raw_file, 'r') as rf:\n",
    "            raw_text = rf.read()\n",
    "        with open(blog_file, 'r') as bf:\n",
    "            blog_text = bf.read()\n",
    "\n",
    "        exact_match_ratio = calculate_exact_match_ratio(raw_text, blog_text)\n",
    "        cosine_sim = calculate_cosine_similarity(raw_text, blog_text)\n",
    "        topic_overlap = calculate_topic_overlap(raw_text, blog_text)\n",
    "        key_phrase_overlap = calculate_key_phrase_overlap(raw_text, blog_text)\n",
    "        semantic_similarity = calculate_semantic_similarity(raw_text, blog_text)\n",
    "        readability_raw = calculate_readability_scores(raw_text)\n",
    "        readability_blog = calculate_readability_scores(blog_text)\n",
    "        sentence_length_raw, _ = analyze_sentence_structure(raw_text)\n",
    "        sentence_length_blog, _ = analyze_sentence_structure(blog_text)\n",
    "\n",
    "        results.append({\n",
    "            \"raw_file\": os.path.basename(raw_file),\n",
    "            \"blog_file\": os.path.basename(blog_file),\n",
    "            \"exact_match_ratio\": exact_match_ratio,\n",
    "            \"cosine_similarity\": cosine_sim,\n",
    "            \"topic_overlap\": topic_overlap,\n",
    "            \"key_phrase_overlap\": key_phrase_overlap,\n",
    "            \"semantic_similarity\": semantic_similarity,\n",
    "            \"readability_raw\": readability_raw,\n",
    "            \"readability_blog\": readability_blog,\n",
    "            \"sentence_length_raw\": sentence_length_raw,\n",
    "            \"sentence_length_blog\": sentence_length_blog\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv('comparison_results.csv', index=False)\n",
    "    return df\n",
    "\n",
    "# Call main function with appropriate folder paths and number of files\n",
    "raw_folder = 'raw_texts'\n",
    "blog_folder = 'Written Blog Posts/4o Blog Raw Text'\n",
    "num_files = 100  # Set the number of files to process\n",
    "\n",
    "results_df_raw_to_4o = process_files_and_calculate_metrics(raw_folder, blog_folder, num_files)\n",
    "\n",
    "# Display results\n",
    "print(results_df_raw_to_4o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_raw_to_4o.to_csv('Individual Comparative CSVs/comparison_results_raw_to_4o.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim import corpora, models\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import textstat\n",
    "import pandas as pd\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Function to calculate Exact Match Ratio\n",
    "def calculate_exact_match_ratio(summary_text, raw_text):\n",
    "    summary_words = set(word_tokenize(summary_text))\n",
    "    raw_words = set(word_tokenize(raw_text))\n",
    "    matches = summary_words.intersection(raw_words)\n",
    "    return len(matches) / len(summary_words)\n",
    "\n",
    "# Function to calculate Cosine Similarity\n",
    "def calculate_cosine_similarity(summary_text, raw_text):\n",
    "    vectorizer = TfidfVectorizer().fit_transform([summary_text, raw_text])\n",
    "    vectors = vectorizer.toarray()\n",
    "    return cosine_similarity(vectors)[0, 1]\n",
    "\n",
    "# Function for Topic Modeling\n",
    "def calculate_topic_overlap(summary_text, raw_text):\n",
    "    documents = [summary_text, raw_text]\n",
    "    dictionary = corpora.Dictionary([word_tokenize(doc) for doc in documents])\n",
    "    corpus = [dictionary.doc2bow(word_tokenize(doc)) for doc in documents]\n",
    "    lda = models.LdaModel(corpus, num_topics=5, id2word=dictionary)\n",
    "    topics_summary = lda.get_document_topics(corpus[0])\n",
    "    topics_raw = lda.get_document_topics(corpus[1])\n",
    "    return compute_topic_overlap(topics_summary, topics_raw)\n",
    "\n",
    "# Helper function to compute topic overlap\n",
    "def compute_topic_overlap(topics_summary, topics_raw):\n",
    "    summary_topics = {topic[0] for topic in topics_summary}\n",
    "    raw_topics = {topic[0] for topic in topics_raw}\n",
    "    overlap = summary_topics.intersection(raw_topics)\n",
    "    return len(overlap) / max(len(summary_topics), len(raw_topics))\n",
    "\n",
    "# Function to extract and compare Key Phrases\n",
    "def calculate_key_phrase_overlap(summary_text, raw_text):\n",
    "    summary_phrases = extract_key_phrases(summary_text)\n",
    "    raw_phrases = extract_key_phrases(raw_text)\n",
    "    matches = set(summary_phrases).intersection(set(raw_phrases))\n",
    "    return len(matches) / len(summary_phrases)\n",
    "\n",
    "# Helper function to extract key phrases (simple implementation)\n",
    "def extract_key_phrases(text):\n",
    "    words = word_tokenize(text)\n",
    "    return list(set(words))  # Simplified: using unique words as key phrases\n",
    "\n",
    "# Function for Semantic Similarity using BERT\n",
    "def calculate_semantic_similarity(summary_text, raw_text):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    def embed_text(text):\n",
    "        inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "        outputs = model(**inputs)\n",
    "        return outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "\n",
    "    summary_embedding = embed_text(summary_text)\n",
    "    raw_embedding = embed_text(raw_text)\n",
    "\n",
    "    print(f\"Summary embedding shape: {summary_embedding.shape}\")\n",
    "    print(f\"Raw text embedding shape: {raw_embedding.shape}\")\n",
    "\n",
    "    if summary_embedding.shape[0] == 1 and raw_embedding.shape[0] == 1:\n",
    "        return cosine_similarity(summary_embedding, raw_embedding)[0, 0]\n",
    "    else:\n",
    "        return 0  # Return 0 similarity if embeddings are not as expected\n",
    "\n",
    "# Function to calculate Readability Scores using textstat\n",
    "def calculate_readability_scores(text):\n",
    "    return textstat.flesch_kincaid_grade(text)\n",
    "\n",
    "# Function to analyze Sentence Length and Structure\n",
    "def analyze_sentence_structure(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    lengths = [len(word_tokenize(sent)) for sent in sentences]\n",
    "    avg_length = sum(lengths) / len(sentences)\n",
    "    return avg_length, lengths\n",
    "\n",
    "# Main function to process files and calculate metrics\n",
    "def process_files_and_calculate_metrics(summary_folder, raw_folder, num_files):\n",
    "    results = []\n",
    "\n",
    "    summary_files = sorted(glob.glob(os.path.join(summary_folder, \"*.txt\")))\n",
    "    raw_files = sorted(glob.glob(os.path.join(raw_folder, \"*.txt\")))\n",
    "\n",
    "    for i in range(num_files):\n",
    "        summary_file = summary_files[i]\n",
    "        raw_file = raw_files[i]\n",
    "\n",
    "        with open(summary_file, 'r') as sf:\n",
    "            summary_text = sf.read()\n",
    "        with open(raw_file, 'r') as rf:\n",
    "            raw_text = rf.read()\n",
    "\n",
    "        exact_match_ratio = calculate_exact_match_ratio(summary_text, raw_text)\n",
    "        cosine_sim = calculate_cosine_similarity(summary_text, raw_text)\n",
    "        topic_overlap = calculate_topic_overlap(summary_text, raw_text)\n",
    "        key_phrase_overlap = calculate_key_phrase_overlap(summary_text, raw_text)\n",
    "        semantic_similarity = calculate_semantic_similarity(summary_text, raw_text)\n",
    "        readability_summary = calculate_readability_scores(summary_text)\n",
    "        readability_raw = calculate_readability_scores(raw_text)\n",
    "        sentence_length_summary, _ = analyze_sentence_structure(summary_text)\n",
    "        sentence_length_raw, _ = analyze_sentence_structure(raw_text)\n",
    "\n",
    "        results.append({\n",
    "            \"summary_file\": os.path.basename(summary_file),\n",
    "            \"raw_file\": os.path.basename(raw_file),\n",
    "            \"exact_match_ratio\": exact_match_ratio,\n",
    "            \"cosine_similarity\": cosine_sim,\n",
    "            \"topic_overlap\": topic_overlap,\n",
    "            \"key_phrase_overlap\": key_phrase_overlap,\n",
    "            \"semantic_similarity\": semantic_similarity,\n",
    "            \"readability_summary\": readability_summary,\n",
    "            \"readability_raw\": readability_raw,\n",
    "            \"sentence_length_summary\": sentence_length_summary,\n",
    "            \"sentence_length_raw\": sentence_length_raw\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv('comparison_results.csv', index=False)\n",
    "    return df\n",
    "\n",
    "# Call main function with appropriate folder paths and number of files\n",
    "summary_folder = 'Written Blog Posts/4o Blog'\n",
    "raw_folder = 'Written Blog Posts/4o Blog Raw Text'\n",
    "num_files = 100  # Set the number of files to process\n",
    "\n",
    "results_df_4o_Sum_to_4o_Raw = process_files_and_calculate_metrics(summary_folder, raw_folder, num_files)\n",
    "\n",
    "# Display results\n",
    "print(results_df_4o_Sum_to_4o_Raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_4o_Sum_to_4o_Raw.to_csv('Individual Comparative CSVs/comparison_results_4o_Sum_to_4o_Raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim import corpora, models\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import textstat\n",
    "import pandas as pd\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Function to calculate Exact Match Ratio\n",
    "def calculate_exact_match_ratio(summary_text, blog_text):\n",
    "    summary_words = set(word_tokenize(summary_text))\n",
    "    blog_words = set(word_tokenize(blog_text))\n",
    "    matches = summary_words.intersection(blog_words)\n",
    "    return len(matches) / len(summary_words)\n",
    "\n",
    "# Function to calculate Cosine Similarity\n",
    "def calculate_cosine_similarity(summary_text, blog_text):\n",
    "    vectorizer = TfidfVectorizer().fit_transform([summary_text, blog_text])\n",
    "    vectors = vectorizer.toarray()\n",
    "    return cosine_similarity(vectors)[0, 1]\n",
    "\n",
    "# Function for Topic Modeling\n",
    "def calculate_topic_overlap(summary_text, blog_text):\n",
    "    documents = [summary_text, blog_text]\n",
    "    dictionary = corpora.Dictionary([word_tokenize(doc) for doc in documents])\n",
    "    corpus = [dictionary.doc2bow(word_tokenize(doc)) for doc in documents]\n",
    "    lda = models.LdaModel(corpus, num_topics=5, id2word=dictionary)\n",
    "    topics_summary = lda.get_document_topics(corpus[0])\n",
    "    topics_blog = lda.get_document_topics(corpus[1])\n",
    "    return compute_topic_overlap(topics_summary, topics_blog)\n",
    "\n",
    "# Helper function to compute topic overlap\n",
    "def compute_topic_overlap(topics_summary, topics_blog):\n",
    "    summary_topics = {topic[0] for topic in topics_summary}\n",
    "    blog_topics = {topic[0] for topic in topics_blog}\n",
    "    overlap = summary_topics.intersection(blog_topics)\n",
    "    return len(overlap) / max(len(summary_topics), len(blog_topics))\n",
    "\n",
    "# Function to extract and compare Key Phrases\n",
    "def calculate_key_phrase_overlap(summary_text, blog_text):\n",
    "    summary_phrases = extract_key_phrases(summary_text)\n",
    "    blog_phrases = extract_key_phrases(blog_text)\n",
    "    matches = set(summary_phrases).intersection(set(blog_phrases))\n",
    "    return len(matches) / len(summary_phrases)\n",
    "\n",
    "# Helper function to extract key phrases (simple implementation)\n",
    "def extract_key_phrases(text):\n",
    "    words = word_tokenize(text)\n",
    "    return list(set(words))  # Simplified: using unique words as key phrases\n",
    "\n",
    "# Function for Semantic Similarity using BERT\n",
    "def calculate_semantic_similarity(summary_text, blog_text):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    def embed_text(text):\n",
    "        inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "        outputs = model(**inputs)\n",
    "        return outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "\n",
    "    summary_embedding = embed_text(summary_text)\n",
    "    blog_embedding = embed_text(blog_text)\n",
    "\n",
    "    print(f\"Summary embedding shape: {summary_embedding.shape}\")\n",
    "    print(f\"Blog text embedding shape: {blog_embedding.shape}\")\n",
    "\n",
    "    if summary_embedding.shape[0] == 1 and blog_embedding.shape[0] == 1:\n",
    "        return cosine_similarity(summary_embedding, blog_embedding)[0, 0]\n",
    "    else:\n",
    "        return 0  # Return 0 similarity if embeddings are not as expected\n",
    "\n",
    "# Function to calculate Readability Scores using textstat\n",
    "def calculate_readability_scores(text):\n",
    "    return textstat.flesch_kincaid_grade(text)\n",
    "\n",
    "# Function to analyze Sentence Length and Structure\n",
    "def analyze_sentence_structure(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    lengths = [len(word_tokenize(sent)) for sent in sentences]\n",
    "    avg_length = sum(lengths) / len(sentences)\n",
    "    return avg_length, lengths\n",
    "\n",
    "# Main function to process files and calculate metrics\n",
    "def process_files_and_calculate_metrics(summary_folder, blog_folder, num_files):\n",
    "    results = []\n",
    "\n",
    "    summary_files = sorted(glob.glob(os.path.join(summary_folder, \"*.txt\")))\n",
    "    blog_files = sorted(glob.glob(os.path.join(blog_folder, \"*.txt\")))\n",
    "\n",
    "    for i in range(num_files):\n",
    "        summary_file = summary_files[i]\n",
    "        blog_file = blog_files[i]\n",
    "\n",
    "        with open(summary_file, 'r') as sf:\n",
    "            summary_text = sf.read()\n",
    "        with open(blog_file, 'r') as bf:\n",
    "            blog_text = bf.read()\n",
    "\n",
    "        exact_match_ratio = calculate_exact_match_ratio(summary_text, blog_text)\n",
    "        cosine_sim = calculate_cosine_similarity(summary_text, blog_text)\n",
    "        topic_overlap = calculate_topic_overlap(summary_text, blog_text)\n",
    "        key_phrase_overlap = calculate_key_phrase_overlap(summary_text, blog_text)\n",
    "        semantic_similarity = calculate_semantic_similarity(summary_text, blog_text)\n",
    "        readability_summary = calculate_readability_scores(summary_text)\n",
    "        readability_blog = calculate_readability_scores(blog_text)\n",
    "        sentence_length_summary, _ = analyze_sentence_structure(summary_text)\n",
    "        sentence_length_blog, _ = analyze_sentence_structure(blog_text)\n",
    "\n",
    "        results.append({\n",
    "            \"summary_file\": os.path.basename(summary_file),\n",
    "            \"blog_file\": os.path.basename(blog_file),\n",
    "            \"exact_match_ratio\": exact_match_ratio,\n",
    "            \"cosine_similarity\": cosine_sim,\n",
    "            \"topic_overlap\": topic_overlap,\n",
    "            \"key_phrase_overlap\": key_phrase_overlap,\n",
    "            \"semantic_similarity\": semantic_similarity,\n",
    "            \"readability_summary\": readability_summary,\n",
    "            \"readability_blog\": readability_blog,\n",
    "            \"sentence_length_summary\": sentence_length_summary,\n",
    "            \"sentence_length_blog\": sentence_length_blog\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv('comparison_results.csv', index=False)\n",
    "    return df\n",
    "\n",
    "# Call main function with appropriate folder paths and number of files\n",
    "summary_folder = 'summaries'\n",
    "blog_folder = 'Written Blog Posts/4o Blog'\n",
    "num_files = 100  # Set the number of files to process\n",
    "\n",
    "results_df_sum_to_4o_blog = process_files_and_calculate_metrics(summary_folder, blog_folder, num_files)\n",
    "\n",
    "# Display results\n",
    "print(results_df_sum_to_4o_blog)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_sum_to_4o_blog.to_csv('Individual Comparative CSVs/comparison_results_sum_to_4o_blog.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim import corpora, models\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import textstat\n",
    "import pandas as pd\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Function to calculate Exact Match Ratio\n",
    "def calculate_exact_match_ratio(blog_text_35t, blog_text_4o):\n",
    "    blog_words_35t = set(word_tokenize(blog_text_35t))\n",
    "    blog_words_4o = set(word_tokenize(blog_text_4o))\n",
    "    matches = blog_words_35t.intersection(blog_words_4o)\n",
    "    return len(matches) / len(blog_words_35t)\n",
    "\n",
    "# Function to calculate Cosine Similarity\n",
    "def calculate_cosine_similarity(blog_text_35t, blog_text_4o):\n",
    "    vectorizer = TfidfVectorizer().fit_transform([blog_text_35t, blog_text_4o])\n",
    "    vectors = vectorizer.toarray()\n",
    "    return cosine_similarity(vectors)[0, 1]\n",
    "\n",
    "# Function for Topic Modeling\n",
    "def calculate_topic_overlap(blog_text_35t, blog_text_4o):\n",
    "    documents = [blog_text_35t, blog_text_4o]\n",
    "    dictionary = corpora.Dictionary([word_tokenize(doc) for doc in documents])\n",
    "    corpus = [dictionary.doc2bow(word_tokenize(doc)) for doc in documents]\n",
    "    lda = models.LdaModel(corpus, num_topics=5, id2word=dictionary)\n",
    "    topics_blog_35t = lda.get_document_topics(corpus[0])\n",
    "    topics_blog_4o = lda.get_document_topics(corpus[1])\n",
    "    return compute_topic_overlap(topics_blog_35t, topics_blog_4o)\n",
    "\n",
    "# Helper function to compute topic overlap\n",
    "def compute_topic_overlap(topics_blog_35t, topics_blog_4o):\n",
    "    blog_topics_35t = {topic[0] for topic in topics_blog_35t}\n",
    "    blog_topics_4o = {topic[0] for topic in topics_blog_4o}\n",
    "    overlap = blog_topics_35t.intersection(blog_topics_4o)\n",
    "    return len(overlap) / max(len(blog_topics_35t), len(blog_topics_4o))\n",
    "\n",
    "# Function to extract and compare Key Phrases\n",
    "def calculate_key_phrase_overlap(blog_text_35t, blog_text_4o):\n",
    "    blog_phrases_35t = extract_key_phrases(blog_text_35t)\n",
    "    blog_phrases_4o = extract_key_phrases(blog_text_4o)\n",
    "    matches = set(blog_phrases_35t).intersection(set(blog_phrases_4o))\n",
    "    return len(matches) / len(blog_phrases_35t)\n",
    "\n",
    "# Helper function to extract key phrases (simple implementation)\n",
    "def extract_key_phrases(text):\n",
    "    words = word_tokenize(text)\n",
    "    return list(set(words))  # Simplified: using unique words as key phrases\n",
    "\n",
    "# Function for Semantic Similarity using BERT\n",
    "def calculate_semantic_similarity(blog_text_35t, blog_text_4o):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    def embed_text(text):\n",
    "        inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "        outputs = model(**inputs)\n",
    "        return outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "\n",
    "    blog_embedding_35t = embed_text(blog_text_35t)\n",
    "    blog_embedding_4o = embed_text(blog_text_4o)\n",
    "\n",
    "    print(f\"3.5t Blog Post embedding shape: {blog_embedding_35t.shape}\")\n",
    "    print(f\"4o Blog Post embedding shape: {blog_embedding_4o.shape}\")\n",
    "\n",
    "    if blog_embedding_35t.shape[0] == 1 and blog_embedding_4o.shape[0] == 1:\n",
    "        return cosine_similarity(blog_embedding_35t, blog_embedding_4o)[0, 0]\n",
    "    else:\n",
    "        return 0  # Return 0 similarity if embeddings are not as expected\n",
    "\n",
    "# Function to calculate Readability Scores using textstat\n",
    "def calculate_readability_scores(text):\n",
    "    return textstat.flesch_kincaid_grade(text)\n",
    "\n",
    "# Function to analyze Sentence Length and Structure\n",
    "def analyze_sentence_structure(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    lengths = [len(word_tokenize(sent)) for sent in sentences]\n",
    "    avg_length = sum(lengths) / len(sentences)\n",
    "    return avg_length, lengths\n",
    "\n",
    "# Main function to process files and calculate metrics\n",
    "def process_files_and_calculate_metrics(blog_folder_35t, blog_folder_4o, num_files):\n",
    "    results = []\n",
    "\n",
    "    blog_files_35t = sorted(glob.glob(os.path.join(blog_folder_35t, \"*.txt\")))\n",
    "    blog_files_4o = sorted(glob.glob(os.path.join(blog_folder_4o, \"*.txt\")))\n",
    "\n",
    "    for i in range(num_files):\n",
    "        blog_file_35t = blog_files_35t[i]\n",
    "        blog_file_4o = blog_files_4o[i]\n",
    "\n",
    "        with open(blog_file_35t, 'r') as bf35t:\n",
    "            blog_text_35t = bf35t.read()\n",
    "        with open(blog_file_4o, 'r') as bf4o:\n",
    "            blog_text_4o = bf4o.read()\n",
    "\n",
    "        exact_match_ratio = calculate_exact_match_ratio(blog_text_35t, blog_text_4o)\n",
    "        cosine_sim = calculate_cosine_similarity(blog_text_35t, blog_text_4o)\n",
    "        topic_overlap = calculate_topic_overlap(blog_text_35t, blog_text_4o)\n",
    "        key_phrase_overlap = calculate_key_phrase_overlap(blog_text_35t, blog_text_4o)\n",
    "        semantic_similarity = calculate_semantic_similarity(blog_text_35t, blog_text_4o)\n",
    "        readability_35t = calculate_readability_scores(blog_text_35t)\n",
    "        readability_4o = calculate_readability_scores(blog_text_4o)\n",
    "        sentence_length_35t, _ = analyze_sentence_structure(blog_text_35t)\n",
    "        sentence_length_4o, _ = analyze_sentence_structure(blog_text_4o)\n",
    "\n",
    "        results.append({\n",
    "            \"blog_file_35t\": os.path.basename(blog_file_35t),\n",
    "            \"blog_file_4o\": os.path.basename(blog_file_4o),\n",
    "            \"exact_match_ratio\": exact_match_ratio,\n",
    "            \"cosine_similarity\": cosine_sim,\n",
    "            \"topic_overlap\": topic_overlap,\n",
    "            \"key_phrase_overlap\": key_phrase_overlap,\n",
    "            \"semantic_similarity\": semantic_similarity,\n",
    "            \"readability_35t\": readability_35t,\n",
    "            \"readability_4o\": readability_4o,\n",
    "            \"sentence_length_35t\": sentence_length_35t,\n",
    "            \"sentence_length_4o\": sentence_length_4o\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv('comparison_results.csv', index=False)\n",
    "    return df\n",
    "\n",
    "# Call main function with appropriate folder paths and number of files\n",
    "blog_folder_35t = 'Written Blog Posts/3.5T Blog'\n",
    "blog_folder_4o = 'Written Blog Posts/4o Blog'\n",
    "num_files = 100  # Set the number of files to process\n",
    "\n",
    "results_df_35blog_sum_to_4oblog_sum = process_files_and_calculate_metrics(blog_folder_35t, blog_folder_4o, num_files)\n",
    "\n",
    "# Display results\n",
    "print(results_df_35blog_sum_to_4oblog_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_35blog_sum_to_4oblog_sum.to_csv('Individual Comparative CSVs/comparison_results_35blog_sum_to_4oblog_sum.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim import corpora, models\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import textstat\n",
    "import pandas as pd\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Function to calculate Exact Match Ratio\n",
    "def calculate_exact_match_ratio(summary_text, raw_text):\n",
    "    summary_words = set(word_tokenize(summary_text))\n",
    "    raw_words = set(word_tokenize(raw_text))\n",
    "    matches = summary_words.intersection(raw_words)\n",
    "    return len(matches) / len(summary_words)\n",
    "\n",
    "# Function to calculate Cosine Similarity\n",
    "def calculate_cosine_similarity(summary_text, raw_text):\n",
    "    vectorizer = TfidfVectorizer().fit_transform([summary_text, raw_text])\n",
    "    vectors = vectorizer.toarray()\n",
    "    return cosine_similarity(vectors)[0, 1]\n",
    "\n",
    "# Function for Topic Modeling\n",
    "def calculate_topic_overlap(summary_text, raw_text):\n",
    "    documents = [summary_text, raw_text]\n",
    "    dictionary = corpora.Dictionary([word_tokenize(doc) for doc in documents])\n",
    "    corpus = [dictionary.doc2bow(word_tokenize(doc)) for doc in documents]\n",
    "    lda = models.LdaModel(corpus, num_topics=5, id2word=dictionary)\n",
    "    topics_summary = lda.get_document_topics(corpus[0])\n",
    "    topics_raw = lda.get_document_topics(corpus[1])\n",
    "    return compute_topic_overlap(topics_summary, topics_raw)\n",
    "\n",
    "# Helper function to compute topic overlap\n",
    "def compute_topic_overlap(topics_summary, topics_raw):\n",
    "    summary_topics = {topic[0] for topic in topics_summary}\n",
    "    raw_topics = {topic[0] for topic in topics_raw}\n",
    "    overlap = summary_topics.intersection(raw_topics)\n",
    "    return len(overlap) / max(len(summary_topics), len(raw_topics))\n",
    "\n",
    "# Function to extract and compare Key Phrases\n",
    "def calculate_key_phrase_overlap(summary_text, raw_text):\n",
    "    summary_phrases = extract_key_phrases(summary_text)\n",
    "    raw_phrases = extract_key_phrases(raw_text)\n",
    "    matches = set(summary_phrases).intersection(set(raw_phrases))\n",
    "    return len(matches) / len(summary_phrases)\n",
    "\n",
    "# Helper function to extract key phrases (simple implementation)\n",
    "def extract_key_phrases(text):\n",
    "    words = word_tokenize(text)\n",
    "    return list(set(words))  # Simplified: using unique words as key phrases\n",
    "\n",
    "# Function for Semantic Similarity using BERT\n",
    "def calculate_semantic_similarity(summary_text, raw_text):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    def embed_text(text):\n",
    "        inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "        outputs = model(**inputs)\n",
    "        return outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "\n",
    "    summary_embedding = embed_text(summary_text)\n",
    "    raw_embedding = embed_text(raw_text)\n",
    "\n",
    "    print(f\"Summary embedding shape: {summary_embedding.shape}\")\n",
    "    print(f\"Raw text embedding shape: {raw_embedding.shape}\")\n",
    "\n",
    "    if summary_embedding.shape[0] == 1 and raw_embedding.shape[0] == 1:\n",
    "        return cosine_similarity(summary_embedding, raw_embedding)[0, 0]\n",
    "    else:\n",
    "        return 0  # Return 0 similarity if embeddings are not as expected\n",
    "\n",
    "# Function to calculate Readability Scores using textstat\n",
    "def calculate_readability_scores(text):\n",
    "    return textstat.flesch_kincaid_grade(text)\n",
    "\n",
    "# Function to analyze Sentence Length and Structure\n",
    "def analyze_sentence_structure(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    lengths = [len(word_tokenize(sent)) for sent in sentences]\n",
    "    avg_length = sum(lengths) / len(sentences)\n",
    "    return avg_length, lengths\n",
    "\n",
    "# Main function to process files and calculate metrics\n",
    "def process_files_and_calculate_metrics(summary_folder, raw_folder, num_files):\n",
    "    results = []\n",
    "\n",
    "    summary_files = sorted(glob.glob(os.path.join(summary_folder, \"*.txt\")))\n",
    "    raw_files = sorted(glob.glob(os.path.join(raw_folder, \"*.txt\")))\n",
    "\n",
    "    for i in range(num_files):\n",
    "        summary_file = summary_files[i]\n",
    "        raw_file = raw_files[i]\n",
    "\n",
    "        with open(summary_file, 'r') as sf:\n",
    "            summary_text = sf.read()\n",
    "        with open(raw_file, 'r') as rf:\n",
    "            raw_text = rf.read()\n",
    "\n",
    "        exact_match_ratio = calculate_exact_match_ratio(summary_text, raw_text)\n",
    "        cosine_sim = calculate_cosine_similarity(summary_text, raw_text)\n",
    "        topic_overlap = calculate_topic_overlap(summary_text, raw_text)\n",
    "        key_phrase_overlap = calculate_key_phrase_overlap(summary_text, raw_text)\n",
    "        semantic_similarity = calculate_semantic_similarity(summary_text, raw_text)\n",
    "        readability_summary = calculate_readability_scores(summary_text)\n",
    "        readability_raw = calculate_readability_scores(raw_text)\n",
    "        sentence_length_summary, _ = analyze_sentence_structure(summary_text)\n",
    "        sentence_length_raw, _ = analyze_sentence_structure(raw_text)\n",
    "\n",
    "        results.append({\n",
    "            \"summary_file\": os.path.basename(summary_file),\n",
    "            \"raw_file\": os.path.basename(raw_file),\n",
    "            \"exact_match_ratio\": exact_match_ratio,\n",
    "            \"cosine_similarity\": cosine_sim,\n",
    "            \"topic_overlap\": topic_overlap,\n",
    "            \"key_phrase_overlap\": key_phrase_overlap,\n",
    "            \"semantic_similarity\": semantic_similarity,\n",
    "            \"readability_summary\": readability_summary,\n",
    "            \"readability_raw\": readability_raw,\n",
    "            \"sentence_length_summary\": sentence_length_summary,\n",
    "            \"sentence_length_raw\": sentence_length_raw\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv('comparison_results.csv', index=False)\n",
    "    return df\n",
    "\n",
    "# Call main function with appropriate folder paths and number of files\n",
    "summary_folder = 'summaries'\n",
    "raw_folder = 'raw_texts'\n",
    "num_files = 100  # Set the number of files to process\n",
    "\n",
    "results_df_sum_to_raw = process_files_and_calculate_metrics(summary_folder, raw_folder, num_files)\n",
    "\n",
    "# Display results\n",
    "print(results_df_sum_to_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_sum_to_raw.to_csv('Individual Comparative CSVs/comparison_results_sum_to_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim import corpora, models\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import textstat\n",
    "import pandas as pd\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Function to calculate Exact Match Ratio\n",
    "def calculate_exact_match_ratio(raw_text, blog_text):\n",
    "    raw_words = set(word_tokenize(raw_text))\n",
    "    blog_words = set(word_tokenize(blog_text))\n",
    "    matches = raw_words.intersection(blog_words)\n",
    "    return len(matches) / len(raw_words)\n",
    "\n",
    "# Function to calculate Cosine Similarity\n",
    "def calculate_cosine_similarity(raw_text, blog_text):\n",
    "    vectorizer = TfidfVectorizer().fit_transform([raw_text, blog_text])\n",
    "    vectors = vectorizer.toarray()\n",
    "    return cosine_similarity(vectors)[0, 1]\n",
    "\n",
    "# Function for Topic Modeling\n",
    "def calculate_topic_overlap(raw_text, blog_text):\n",
    "    documents = [raw_text, blog_text]\n",
    "    dictionary = corpora.Dictionary([word_tokenize(doc) for doc in documents])\n",
    "    corpus = [dictionary.doc2bow(word_tokenize(doc)) for doc in documents]\n",
    "    lda = models.LdaModel(corpus, num_topics=5, id2word=dictionary)\n",
    "    topics_raw = lda.get_document_topics(corpus[0])\n",
    "    topics_blog = lda.get_document_topics(corpus[1])\n",
    "    return compute_topic_overlap(topics_raw, topics_blog)\n",
    "\n",
    "# Helper function to compute topic overlap\n",
    "def compute_topic_overlap(topics_raw, topics_blog):\n",
    "    raw_topics = {topic[0] for topic in topics_raw}\n",
    "    blog_topics = {topic[0] for topic in topics_blog}\n",
    "    overlap = raw_topics.intersection(blog_topics)\n",
    "    return len(overlap) / max(len(raw_topics), len(blog_topics))\n",
    "\n",
    "# Function to extract and compare Key Phrases\n",
    "def calculate_key_phrase_overlap(raw_text, blog_text):\n",
    "    raw_phrases = extract_key_phrases(raw_text)\n",
    "    blog_phrases = extract_key_phrases(blog_text)\n",
    "    matches = set(raw_phrases).intersection(set(blog_phrases))\n",
    "    return len(matches) / len(raw_phrases)\n",
    "\n",
    "# Helper function to extract key phrases (simple implementation)\n",
    "def extract_key_phrases(text):\n",
    "    words = word_tokenize(text)\n",
    "    return list(set(words))  # Simplified: using unique words as key phrases\n",
    "\n",
    "# Function for Semantic Similarity using BERT\n",
    "def calculate_semantic_similarity(raw_text, blog_text):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    def embed_text(text):\n",
    "        inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "        outputs = model(**inputs)\n",
    "        return outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "\n",
    "    raw_embedding = embed_text(raw_text)\n",
    "    blog_embedding = embed_text(blog_text)\n",
    "\n",
    "    print(f\"Raw text embedding shape: {raw_embedding.shape}\")\n",
    "    print(f\"Blog embedding shape: {blog_embedding.shape}\")\n",
    "\n",
    "    if raw_embedding.shape[0] == 1 and blog_embedding.shape[0] == 1:\n",
    "        return cosine_similarity(raw_embedding, blog_embedding)[0, 0]\n",
    "    else:\n",
    "        return 0  # Return 0 similarity if embeddings are not as expected\n",
    "\n",
    "# Function to calculate Readability Scores using textstat\n",
    "def calculate_readability_scores(text):\n",
    "    return textstat.flesch_kincaid_grade(text)\n",
    "\n",
    "# Function to analyze Sentence Length and Structure\n",
    "def analyze_sentence_structure(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    lengths = [len(word_tokenize(sent)) for sent in sentences]\n",
    "    avg_length = sum(lengths) / len(sentences)\n",
    "    return avg_length, lengths\n",
    "\n",
    "# Main function to process files and calculate metrics\n",
    "def process_files_and_calculate_metrics(raw_folder, blog_folder, num_files):\n",
    "    results = []\n",
    "\n",
    "    raw_files = sorted(glob.glob(os.path.join(raw_folder, \"*.txt\")))\n",
    "    blog_files = sorted(glob.glob(os.path.join(blog_folder, \"*.txt\")))\n",
    "\n",
    "    for i in range(num_files):\n",
    "        raw_file = raw_files[i]\n",
    "        blog_file = blog_files[i]\n",
    "\n",
    "        with open(raw_file, 'r') as rf:\n",
    "            raw_text = rf.read()\n",
    "        with open(blog_file, 'r') as bf:\n",
    "            blog_text = bf.read()\n",
    "\n",
    "        exact_match_ratio = calculate_exact_match_ratio(raw_text, blog_text)\n",
    "        cosine_sim = calculate_cosine_similarity(raw_text, blog_text)\n",
    "        topic_overlap = calculate_topic_overlap(raw_text, blog_text)\n",
    "        key_phrase_overlap = calculate_key_phrase_overlap(raw_text, blog_text)\n",
    "        semantic_similarity = calculate_semantic_similarity(raw_text, blog_text)\n",
    "        readability_raw = calculate_readability_scores(raw_text)\n",
    "        readability_blog = calculate_readability_scores(blog_text)\n",
    "        sentence_length_raw, _ = analyze_sentence_structure(raw_text)\n",
    "        sentence_length_blog, _ = analyze_sentence_structure(blog_text)\n",
    "\n",
    "        results.append({\n",
    "            \"raw_file\": os.path.basename(raw_file),\n",
    "            \"blog_file\": os.path.basename(blog_file),\n",
    "            \"exact_match_ratio\": exact_match_ratio,\n",
    "            \"cosine_similarity\": cosine_sim,\n",
    "            \"topic_overlap\": topic_overlap,\n",
    "            \"key_phrase_overlap\": key_phrase_overlap,\n",
    "            \"semantic_similarity\": semantic_similarity,\n",
    "            \"readability_raw\": readability_raw,\n",
    "            \"readability_blog\": readability_blog,\n",
    "            \"sentence_length_raw\": sentence_length_raw,\n",
    "            \"sentence_length_blog\": sentence_length_blog\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv('comparison_results.csv', index=False)\n",
    "    return df\n",
    "\n",
    "# Call main function with appropriate folder paths and number of files\n",
    "raw_folder = 'raw_texts'\n",
    "blog_folder = 'Written Blog Posts/4o Blog'\n",
    "num_files = 100  # Set the number of files to process\n",
    "\n",
    "results_df_raw_to_4o_sum_blog = process_files_and_calculate_metrics(raw_folder, blog_folder, num_files)\n",
    "\n",
    "# Display results\n",
    "print(results_df_raw_to_4o_sum_blog)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_sum_to_raw.to_csv('Individual Comparative CSVs/comparison_results_raw_to_4o_sum_blog.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
