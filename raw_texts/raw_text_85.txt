1
2
0
2

r
p
A
5
1

]

C
D
.
s
c
[

1
v
4
7
5
7
0
.
4
0
1
2
:
v
i
X
r
a

Who Needs Consensus? A Distributed Monetary System Between Rational
Agents via Hearsay

YANNI GEORGHIADES, The University of Texas at Austin, United States
ROBERT STREIT, The University of Texas at Austin, United States
VIJAY GARG, The University of Texas at Austin, United States

We propose a novel distributed monetary system called Hearsay that tolerates both Byzantine and rational behavior without the need

for agents to reach consensus on executed transactions. Recent work [5, 10, 15] has shown that distributed monetary systems do not

require consensus and can operate using a broadcast primitive with weaker guarantees, such as reliable broadcast. However, these

protocols assume that some number of agents may be Byzantine and the remaining agents are perfectly correct. For the application

of a monetary system in which the agents are real people with economic interests, the assumption that agents are perfectly correct

may be too strong. We expand upon this line of thought by weakening the assumption of correctness and instead adopting a fault
tolerance model which allows up to ð¡ < ð
3 agents to be Byzantine and the remaining agents to be rational. A rational agent is
one which will deviate from the protocol if it is in their own best interest. Under this fault tolerance model, Hearsay implements

a monetary system in which all rational agents achieve agreement on executed transactions. Moreover, Hearsay requires only a

single broadcast per transaction. In order to incentivize rational agents to behave correctly in Hearsay, agents are rewarded with

transaction fees for participation in the protocol and punished for noticeable deviations from the protocol. Additionally, Hearsay

uses a novel broadcast primitive called Rational Reliable Broadcast to ensure that agents can broadcast messages under Hearsayâs

fault tolerance model. Rational Reliable Broadcast achieves equivalent guarantees to Byzantine Reliable Broadcast [7] but can tolerate

the presence of rational agents. To show this, we prove that following the Rational Reliable Broadcast protocol constitutes a Nash

equilibrium between rational agents. We deem Rational Reliable Broadcast to be a secondary contribution of this work which may

be of independent interest.

1 INTRODUCTION

Distributed monetary systems have risen in popularity in recent years in large part due to the success of Bitcoin [23]

and the ï¬ood of distributed money transfer protocols which followed it. Broadly, these protocols can be categorized

into three groups: protocols which require agents to solve Nakamoto consensus [23], protocols which require agents

to solve Byzantine fault tolerant consensus (which we often refer to as âclassical consensusâ) [14], and protocols which

require weaker notions of agreement than consensus such as reliable broadcast [7].

The most popular category of distributed money transfer protocols consists of work which aims to improve on

Nakamoto consensus. While great headway has been made, Nakamoto consensus still has several drawbacks. The

most notorious ones are its limited transaction throughput and high transaction settlement times, which are in many

ways a byproduct of its lack of ï¬nality in executed transactions. Additionally, to the best of our knowledge, there have

been no variants of Nakamoto consensus proposed which do not assume that some amount of decision-making power

(typically hashing power for Proof-of-Work [11]) in the system is correct.

The next most prominent category of distributed money transfer protocols includes protocols which use more clas-

sical Byzantine fault tolerant consensus protocols such as PBFT to agree upon executed transactions. These protocols

typically oï¬er transaction ï¬nality, but it comes at a cost. In general, classical consensus is a notoriously diï¬cult problem

to solve in asynchronous systems [14] and is expensive in terms of both time and message complexity. Additionally,

1

 
 
 
 
 
 
Yanni Georghiades, Robert Streit, and Vijay Garg

whereas Nakamoto consensus requires only a strict majority of correct decision-making power, classical consensus
requires that greater than 2

3 of the agents in the system are correct.

The thirdâand most relevantâcategory of distributed money transfer protocols is composed of protocols which do

not require any form of consensus, instead opting for a less costly form of agreement. In particular, a line of recent

work [5, 10, 15] in distributed money transfer protocols which rely weaker broadcast primitives is a key source of

inspiration for Hearsay. The work of Guerraoui et. al. observes that the consensus number [19] of a distributed money

transfer protocol is 1 and proposes a money transfer protocol which relies on secure reliable multicast [22] in lieu of

consensus. Following this work, Collins et. al. propose and implement a protocol called Astro which uses only a single

reliable broadcast [7] per transaction. Similarly, Auvolat et. al. presents a simpliï¬ed and generic money transfer proto-

col which also uses only a single reliable broadcast per transaction. Following a slightly diï¬erent approach, ABC [26]

is a Proof-of-Stake protocol which also requires only a weak form of consensus which does not require termination for

messages with Byzantine senders. Notably, each of these protocols assumes the same fault tolerance model in which
more than 2
3 of agents must be correct. This assumption is quite reasonable for many applications in distributed com-
puting, but it may be too strong for a money transfer system in which agents are inherently economically motivated.

It seems optimistic to assume that a substantial number of agents would remain correct if deviating from the protocol

would provide greater money or lower costs. In order to counteract this type of self-serving behavior, we forego the
assumption of correctness and instead assume that at least 2
3 of agents are rational. We extend the works of [5, 10, 15]
by instilling mechanisms into the money transfer protocol which cause rational agents to prefer following the protocol

over deviating.

In this work we present a novel distributed monetary system called Hearsay that tolerates both Byzantine and

rational behavior and operates without the need for consensus. Speciï¬cally, we contribute:

â¢ The Hearsay protocol, a distributed monetary system that tolerates up to ð¡ < ð

3 Byzantine agents and assumes

the remaining agents to be rational.

â¢ The Rational Reliable Broadcast protocol, a variant of reliable broadcast that that also tolerates up to ð¡ < ð
3

Byzantine agents and assumes the remaining agents to be rational.

â¢ Formal analysis and guarantees of Hearsay and Rational Reliable Broadcast in a game theoretic environment.

In Section 2, we summarize the related work that inï¬uenced our research. We overview distributed money transfer

systems which use Nakamoto consensus and Byzantine fault tolerant consensus, distributed money transfer systems

which require weaker guarantees than consensus, and other examples of applications of game theory in distributed

computation. In Section 3, we describe our model which assumes that a bounded number of agents are Byzantine while

the remainder are rational. In Section 4, we present Rational Reliable Broadcast (RRB), a secondary contribution of this

work. RRB is a variant of the reliable broadcast protocol which operates in game theoretic environments. Not only do

we show correctness in the presence of Byzantine faults, but also that our incentive mechanisms cause rational agents

to behave correctly. Speciï¬cally, we show that following the RRB protocol is a Nash equilibrium. Rational Reliable

Broadcast is the backbone of transaction broadcast in Hearsay, but we also believe that a reliable broadcast protocol

with safety and liveness guarantees in the presence of rational agents is of independent interest. In Section 5 we

describe Hearsay, the main contribution of this work. We provide pseudo-code for the Hearsay protocol and prove

that it satisï¬es Validity, Agreement, and Integrity as deï¬ned in Section 5.4. Hearsay achieves these properties in the

presence of rational agents by imposing rewards for participation and punishments for deviation from the protocol

through a transaction fee system. Section 6 examines this dynamic in depth, proving that correct behavior in the

2

Who Needs Consensus? A Distributed Monetary System Between Rational Agents via Hearsay

Hearsay protocol is a Nash equilibrium, as no rational agent can do better (gain more utility) by deviating from the

protocol speciï¬cation. Finally in Section 7 we reï¬ect and discuss avenues for future work.

2 RELATED WORK

This paper extends a line of recent work in distributed monetary systems [5, 10, 15] which do not require consensus

on transactions. Instead, [15] uses secure reliable multicast [22] and both [10] and [5] use reliable broadcast [7] for

broadcasting messages. Both broadcast protocols oï¬er weaker guarantees than consensus, including a guarantee of

source order rather than total order on message deliveries and a lack of any delivery guarantee for messages from

Byzantine senders. However, each of these papers makes use of the classical fault tolerance model in which up to
ð¡ < ð
3 of agents may be Byzantine and the rest are assumed to be correct. In a monetary system in which the agents
are entities with economic interests, this assumption of correctness may not hold in practice. Hearsay does not depend
on consensus and assumes a weakened fault tolerance model inspired by [4]. In Hearsay, up to ð¡ < ð
3 of agents may be
Byzantine and the rest are assumed to be rational, meaning they will deviate from the protocol if it is in their own best

interest. In order to accommodate for this weaker fault tolerance model, we add mechanisms to both the Byzantine

reliable broadcast protocol from [7] and to the monetary system from [5] which incentivize rational agents to behave

as correct agents.

There have been numerous distributed money transfer protocols proposed recently, and the protocols which require

a form of consensus on executed transactions can be broadly categorized into two groups. The ï¬rst group of protocols

[12, 21, 27] consists of those that adopt a model similar to that of Bitcoin. Bitcoin uses a blockchain to achieve Nakamoto
consensus in asynchronous networks under the stated assumption that less than 1
2 of the decision-making power (in
this case, hashing power to be used for Proof-of-Work) is controlled by Byzantine agents and the remaining power is

controlled by correct agents [24]. Later work shows that following the Bitcoin protocol is not incentive-compatible if all

agents are assumed to be rational [8, 13]. Another approach to improving blockchain-based money transfer protocols

is to replace Nakamoto consensus with a more classical Byzantine fault tolerant consensus protocol such as PBFT

[9]. These protocols [3, 25] typically oï¬er more classical safety and liveness guarantees than Nakamoto consensus,
such as transaction ï¬nality. However, they still adopt the fault tolerance model that up to ð¡ < ð
3 of agents may be
Byzantine and that the rest are correct. In an approach slightly more similar to that of Hearsay, ABC [26] implements

a distributed money transfer protocol which requires only a relaxed form of consensus on transactions. ABC is able to
achieve transaction ï¬nality under the familiar assumption that up to ð¡ < ð
3 of the decision-making power (in this case,
asset ownership to be used for Proof-of-Stake) is controlled by Byzantine agents and the remaining power is controlled

by correct agents. While Hearsay is a permissioned system and therefore operates under a diï¬erent execution model

from the permissionless protocols, we hold these protocols up as points of contrast in order to highlight the novelty

of Hearsay. Hearsay does not require consensusâeither Nakamoto or classicalâon transactions, but Hearsayâs most

signiï¬cant deviation from previous distributed monetary systems is in its fault tolerance model, which foregoes any

assumption that a majority of agents will behave correctly and instead assumes that these agents will behave rationally.

There have been a few papers in recent years which apply rationality assumptions to distributed computing proto-

cols. Despite the stated fault tolerance model used by Bitcoin, some argue that the Bitcoin protocol is indeed incentive

compatible if all agents are rational [6], and the eï¬ectiveness of transaction fees and block rewards in the Bitcoin im-

plementation supports this claim to some degree. More explicitly, [4] introduces the BAR fault tolerance model, which

captures three types of behavior: Byzantine, altruistic (i.e., correct), and rational. The same work introduces BAR-B,

an asynchronous replicated state machine which achieves safety and liveness guarantees under the BAR model. The

3

Yanni Georghiades, Robert Streit, and Vijay Garg

local retaliation policy used in Rational Reliable Broadcast is inspired by a similar policy used in BAR-B, and the fault

tolerance model used in Hearsay is identical to the BAR model except that in Hearsay there are no altruistic agents.

In the application of multiparty computation, [17] shows that multiparty computation is incentive compatible under

the assumption that all agents are rational. Extending this work, [2] shows the same result even if some agents behave

unexpectedly and some agents collude in an attempt to increase their utility.

3 MODEL

We consider a system of N agents which store their own outgoing transaction log and a local view of the balance of each

other agent. Agents communicate via direct, asynchronous, and reliable channels with bounded transmission times.

We assume that channels are authenticated, so messages sent can be attributed to their initiator and the integrity of

messages can be conï¬rmed. The system is permissioned, and all agents are known to each other before communication
begins. We allow up to ð¡ < ð
3 agents to be Byzantine, meaning they may exhibit arbitrary behavior. This includes but
is not limited to faulty behavior, collusion, and malice against other participants.

The remaining agents are assumed to be rational, meaning that they make decisions which maximize their own

utility gain or rewards. Rational agents follow the protocol correctly if it is in their best interest to do so, but will deviate

if they perceive a better outcome as a result. Such an assumption is highly applicable in ï¬nancial systems, such as the

monetary system we consider in this work, because the application connects directly with ideas of loss and gain. This

means that we cannot simply show that our protocols are tolerant to Byzantine behavior, but we must also show that

rational agents are incentivized to behave correctly. In our results we show that correct behavior is a Nash equilibrium

amongst the rational agents. This means that under the assumption that all other rational agents are following the

protocol, no agent can gain more utility by deviating from the protocol than by behaving correctly. This argument

shows that all rational agents behave correctly as doing otherwise could only reduce their expected utility gain. In

proving these game theoretic results, we assume that there are no externalities available to rational agents, such as

extra communication, collusion, or non-rational behaviors such as spite (naturally Byzantine agents may still exhibit

arbitrary behavior including these externalities). Examining our results in systems which allow collusion between

rational agents is an interesting avenue of future work.

4 RATIONAL RELIABLE BROADCAST

Agents in the Hearsay protocol uses reliable broadcast [7] in order to communicate messages. Since we assume the

non-Byzantine agents are rational, they may not execute the reliable broadcast protocol correctly if they see a beneï¬t in

deviating. For example, if there is a cost associated with forwarding a message and an agent believes their participation

is not instrumental (i.e. the rest of the network will âtake care of itâ), then they will not forward messages. In the social

sciences this is referred to as the free rider problem, the idea that rational agents will choose to reap the beneï¬ts of

a service without contributing to it. Due to the large number of rational agents in our model, we must be careful in

designing a suitable reliable broadcast protocol that overcomes these challenges. The following section details a novel

broadcast protocol called Rational Reliable Broadcast (RRB) that we use to broadcast transactions in Hearsay.

We start with the foundational Byzantine reliable broadcast protocol (BRB) from [7]. BRB assumes that up to ð¡ < ð
3
agents may be Byzantine and the remaining agents are correct. The fault tolerance model used by Hearsay assumes
that up to ð¡ < ð
3 agents may be Byzantine but that the remaining agents are rational instead of correct. Agents in RRB
follow a simple retaliation policy in order to guarantee fault tolerance under our model.

4

Who Needs Consensus? A Distributed Monetary System Between Rational Agents via Hearsay

Each agent in Hearsay runs ð separate RRB instancesâone for each agentâand an agentâs ðð¡â RRB instance is for
participating in broadcasts initiated by agent ð ð . We use this understanding in the speciï¬cation of our reliable broadcast
protocol and in our proofs. An equivalent view of this speciï¬cation is that each agent has a separate broadcast channel,
where the ðð¡â channel is owned by agent ðð and ðð is the only agent allowed to initiate broadcasts in this channel. Then
when an agent executes any part of the RRB protocol on a particular instance, it accesses only the sequence numbers,

queues, and variables pertinent to that instance, and retaliation can be performed within a single instance without
impacting any other instance. A RRB instance where agent ðâ is the initiator satisï¬es the following properties.

Validity. If a rational agent ðâ broadcasts a message ð, then ðâ eventually delivers ð.
Agreement. If a rational agent delivers a message ð, then all rational agents eventually deliver ð.
Integrity. For any agent ðâ and sequence number ð , every rational agent delivers at most one message ð initiated by
ðâ with sequence number ð . Moreover, this delivery only occurs if ð was previously broadcast by ðâ.

These properties mimic those of BRB [16] except that they provide guarantees with respect to rational agents rather

than correct agents. To achieve these properties, we adopt a mechanism used by [4] with some minor modiï¬cations.

In particular, agents impose the following localized penalty in reliable broadcast communications against other agents

who deviate from the correct protocol execution.

Definition 4.1 (Retaliation). Consider an instance of RRB called ðµ. Suppose ðµ is tasked with broadcasting a message,
and has a sequence number ð  internal to its instance of the protocol. If an agent ðð does not receive a message from another
agent ð ð within the execution of ðµ for sequence number ð , then ðð retaliates by stopping communications with ð ð in protocol
instance ðµ for any future sequence number ð  â² > ð  until ðð receives the missing messages from ð ð for instance ðµ, sequence
number ð .

This mechanism is intended to punish lazy agents who attempt to reduce their communication costs in the reliable

broadcast protocol. Observe that without this mechanism, lazy agents may listen to incoming messages but never send

any outgoing messages.

4.1 RRB Protocol Description

The full Rational Reliable Broadcast protocol is essentially the protocol from [7], with a retaliation penalty added using

a message queuing system. This queuing system updates vectors tracking the sequence numbers of the last messages

received by each other agent and delays sending messages out about a sequence number ð  to a certain agent ð until all
messages regarding sequence numbers up to and including ð  â 1 have been processed. For the sake of self-containment,

we reproduce the full algorithm in Algorithm 2. For brevity, presentation is deferred to Appendix A

In words, Algorithm 2 describes the following: An agent ðâ initiates a broadcast in the RRB instance by marking
their message with the tag initial and sending it to each other agent. An agent receiving a message msg forwards the
contents with the tag echo after one of two conditions occur. Either the agent received msg from ðâ itself in an initial
message, or it has received enough echo or ready messages to ensure that ðâ was the initial sender of msg. An agent
sends a ready message when it knows that msg is the only message broadcast by ðâ for that sequence number. This
can be guaranteed because the ï¬rst agent to send a ready message must have seen (ð + ð¡)/2 echo messages, and two

separate agents cannot receive this many echo messages for distinct message contents because that would imply that

a correct agent sent multiple echo messages for diï¬erent message contents. This portion of the algorithm is essentially

unchanged from [7], so the reader can ï¬nd more information there.

5

Yanni Georghiades, Robert Streit, and Vijay Garg

To enable retaliation against lazy processes, a queuing system is used to process messages in order of sequence

number. This queuing system allows agent to detect if another agent has neglected their duties of participating in an

instance and exclude this agent from their communications within this instance until the missing messages are received.

Separate queues are used for incoming echo, incoming ready, and outgoing messages. When an echo or ready message

is received, it is not processed until all messages with lesser sequence numbers are cleared from the queue. Likewise

when the outgoing queue is ï¬ushed, outgoing messages to agents that have not sent messages for prior sequences is

delayed until this is remedied. Queues are ï¬ushed whenever an agentâs knowledge changes on receiving a message.

Within the ï¬ushing routine are blocks to ensure multiple messages from an agent for the same sequence number

are ignored. Within the protocol are also checks to ensure that a correct agent does not send duplicate messages, so

these blocks ensure that correct agents do not exhibit deviant behavior such as sending multiple initial messages with
diï¬erent contents for the same sequence number. 1

4.2 RRB Correctness

To show the correctness of RRB, we ï¬rst show that the retaliation penalty in Deï¬nition 4.1 is suï¬cient to guarantee

that all rational agents behave correctly so long as they believe that all other rational agents will also behave correctly.

We ï¬rst make the following assumption:

Assumption 1. Agents have a preference towards a (2ð¡ + 1)-sized quorum signalling âreadyâ over not in Rational

Reliable Broadcast, due to the context the protocol is being used in.

When we refer to the context of the protocolâs deployment, we mean whether the use case implies rewards for

participation or is directly linked to utility gain such as in a money transfer system. It is easy to argue that this

assumption is achievable in Hearsay. In Hearsay, all agents are given a reward in the form of a transaction fee when a

transaction is executed. As we will see in Section 5, a transaction cannot be executed before it is delivered, which does

not occur until a quorum is reached. Therefore, in our context, agents will prefer these quorums to form as otherwise

they may be blocked from reward, and even correctly interacting with the broadcast (i.e. send and receive funds) with

the initiator of the broadcast channel. It is for this reason we have the following conditional result:

Corollary 4.2. Predicated on Assumption 1, rational agents prefer to be a member of (2ð¡ +1)-sized quorums signalling

âreadyâ in Rational Reliable Broadcast

Proof. This is due to a âfear of missing outâ on successful quorums. This is because in the worst case (i.e., when
there are ð¡ = â ð
3 â â 1 Byzantine agents who choose not to participate in the RRB instance), a rational agentâs choice to
abstain from participating in a broadcast will make a (2ð¡ + 1)-sized quorum impossible to achieve. Suppose the worst

case occurs with nonzero probability. During any execution of Rational Reliable Broadcast, a rational agent is tasked

with reasoning about whether it is better to abstain to lessen the costs of communication or join the quorum to ensure

they receive positive utility. In the worst case, a rational agent is pivotal in ensuring a quorum occurs, so a reward in

the context of Assumption 1 can be made large enough such that the expected utility, when considering the probability

of the worst case outcome, is larger than any costs against participating in the quorum. This gives the result.

Furthermore, suppose we impose an assumption similar one used in [4], which assumes that rational agents assign

high weight to the probability of worst case behavior (i.e. rational agents are risk averse). This would be because

1We remark that this retaliation mechanism does impact performance, as we are forcing agents to react to messages from other agents in order of
sequence numbers. An interesting direction for future work would be to examine this performance impact or design alternate incentive mechanisms for
reliable broadcast in the presence of rational agents.

6

Who Needs Consensus? A Distributed Monetary System Between Rational Agents via Hearsay

they value the beneï¬ts of the service and view the risk of service failure as unacceptable, which is not far-fetched in
infrastructural technologies such as monetary systems2. Then this precludes the quantity of a suitable reward from
(cid:3)
being prohibitively large.

We now show that rational agents behave according to the protocol in RRB.

Lemma 4.3. No rational agent has a unilateral incentive to deviate from the RRB protocol.

Proof. Fix a RRB instance ðµ, initiating agent ðâ, and sequence number ð . First notice that no agent has any incentive
to send extra echo and ready messages: Indeed lines 9 and 15 ensure correct agents ignore such behavior in a single

sequence, so conditioning on the other rational agents following the protocol, no agent can gain anything by sending

extra echo and ready messages. Similar logic applies for sending multiple initial messages for a single sequence, as

analysis in [7], and given intuitively in the description of the algorithm, show that given the other rational agents are

behaving correctly, only one of the initial messages will be accepted by the rational agents. Therefore we are interested

in showing that rational agents cannot beneï¬t by abstaining from forwarding messages in the protocol (i.e. we prove

there are no free riders).

Let ðbad be a deviating agent which does not send messages to agent ðvictim for the reliable broadcast initiated by ðâ
for sequence ð . By the retaliation policy, ðvictim will refuse to send messages to ðbad about broadcasts from initiator ðâ
with sequence number greater than ð . In the worst case, ðbad will be unable to participate in quorums of 2ð¡ + 1 âreadyâ
signals on any future transaction from ðâ. By Corollary 4.2 any rational agent would prefer to not be in this situation.
(cid:3)
Therefore a rational agent has no unilateral incentive to deviate from the RRB protocol.

Remark 4.4. When we argued Corollary 4.2 , we pointed out that in the worst case a rational agent ðbad choosing to
abstain from participation in the RRB protocol could lead to a âstalledâ broadcast instance for the initiating agent ðâ. In
this case the retaliation other agents enact on ðbad is in some ways giving ðbad control over the broadcast capabilities of ðâ,
and ðbad could ransom these capabilities to force ðâ to pay them to un-stall their channel. Under the assumption that no
externalities, such as extra communication channels, are present among rational agents, this attack is impossible. It would

be interesting future work to examine what dynamics may arise when such externalities are present.

Now we can prove the protocol is correct.

Theorem 4.5. The Rational Reliable Broadcast protocol is correct, i.e. it satisï¬es the validity, agreement, and integrity

properties.

Proof. The only changes to the BRB protocol given in [7] are the queuing and retaliation systems. As we assume

reliable (but still asynchronous) communication, the queuing system should then have no impact on the activities of the

rational agents. Likewise the retaliation system will have no impact on the activities between rational agents, as Lemma

4.3 shows that rational agents behave correctly. Therefore each of the properties is inherited from [7]. In particular,

validity and agreement are shown by property 1, which is proven in Theorem 1 and Lemma 4 in [7]. Integrity simply

follows by Algorithm 2, as duplicate messages are ignored and the delivery of a message can only happen once for each

sequence number. Additionally, 38 of Algorithm 2 states that a correct agent must see more echo or ready messages than

there are Byzantine agents, meaning only messages correctly initiated by the sender are able be delivered. Integrity
(cid:3)

follows.
2Moreover, notice that behavior such as the formation of mining pools (see [20]) in cryptocurrencies suggests that participants in distributed monetary
systems are naturally risk averse, as this widespread strategy is done speciï¬cally to reduce risk.

7

Yanni Georghiades, Robert Streit, and Vijay Garg

5 THE HEARSAY PROTOCOL

In this section, we describe the Hearsay protocol and provide pseudo-code in Algorithm 1. Hearsay operates with ð

fully-connected and uniquely identiï¬ed agents, and each agent maintains a public-private key pair for signing and

authenticating messages. The only messages that are broadcast in Hearsay are transactions messages, in which the

agent initiating the broadcast speciï¬es an amount of money to be transferred to a single recipient agent. Additionally,

the initiating agent must pay a ï¬xed transaction fee ð to each other agent in the system upon execution of a transaction.
The state of the system is replicated across each agent in the form of local variables B, a vector of balances for
each agent, and S, a list of agent sequence numbers which allow the outgoing transactions of each agent to be totally

ordered. Additionally, each agent maintains a set of incoming payment buï¬ers and a set of fee buï¬ers, which contain

incoming payments and fees, respectively, for each agent which have not yet been credited to their balance. When

an agent initiates a new transaction, they can specify the incoming payments and fees which must be added to their

balance prior to executing the transaction.

5.1 Rational Reliable Broadcast in Hearsay

Hearsay makes use of ð instances of the RRB protocol to enable broadcasts between agents. All agents participate in

all of the RRB instances, but each agent is only allowed to initiate a broadcast in a single instance.

In order to maintain modularity between Hearsay and the underlying broadcast primitive, we introduce the follow-

ing vocabulary. An agent broadcasts a transaction if they construct the transaction, sign it, and send it to all other

agents. An agent ð receives a transaction if it is sent to them during execution of an RRB instance. After achieving a

suï¬cient quorum on a received transaction to satisfy the broadcast primitive, ð then delivers the transaction by adding

it to a buï¬er containing transactions to be executed after a set of conditions are satisï¬ed. Once the required conditions

are met, ð executes a delivered transaction by running the Execute function. Finally, if ð determines that the transac-

tion is not a bad transaction, then ð commits the transaction by updating the balances of the initiator and recipient

accordingly.

This modularity allows messages to be delivered in each RRB instance without any constraints from the Hearsay

protocol while ensuring that transactions are executed in accord with certain dependency conditions (as speciï¬ed in

Algorithm 1).

5.2 Protocol Description

Money transfer begins when an agent constructs a transaction with the Pay function. A transaction consists of the
following elements: 1) the index of a source agent ð from which money will be deducted, 2) the index of a destination
agent ð which will receive the money, 3) an expenditure amount ð¥ that will be transferred from agent ð to agent ð, 4)
the sequence number of agent ðâs outgoing transaction, and 5, 6) a set of recent payments and fees received by agent ð

which are used to verify that ðâs balance is suï¬cient to make the transfer.

After composing a transaction, ð broadcasts it using the RRB primitive. Each agent delivers any transaction for

which they receive a RRB quorum. In the case that a transaction never achieves a RRB quorum, it is clear by the

Validity property of RRB that the initiator of the transaction must be Byzantine, and the transaction therefore does not

need to be delivered.

Upon delivering a transaction, an agent places the transaction into a buï¬er until the following conditions are met.

The ï¬rst condition is that, in order for an agent to execute a transaction with initiator ð and sequence number ð , their

8

Who Needs Consensus? A Distributed Monetary System Between Rational Agents via Hearsay

local sequence number for initiator ð must be ð  â 1. This ensures that any correct agent executes all transactions from

ð in order of sequence number. The second condition which must be met before a transaction can be executed is that

all of its dependent transactions must be executed. Because communication is asynchronous and agents may execute

transactions in diï¬erent order, the second condition is imposed to guarantee that any money received by the initiator

of a transaction which is required for the initiator to pass a balance check is indeed added to their balance before

their transaction is executed. The third and ï¬nal condition which must be met before a transaction may be executed

is that the initiator of the transaction must either have a balance of ð ð prior to the execution of the transaction or

the transaction must convert at least ð fee credits into balance. This condition guarantees that no agent can achieve a

negative balance (i.e., go into debt). Without checking the third condition prior to execution, any agent with a balance

of less than ð ð which initiates a transaction will end up with a negative balance, as fees are deducted from the initiatorâs

balance regardless of whether or not the transaction is committed.

Agents execute a transaction by updating their local variables according to the Execute function. While executing

a transaction, each agent must verify that the agent which initiated the transaction has suï¬cient balance to cover

both the speciï¬ed payment and the required transaction fees. If an agent executing a transaction determines that the

initiating agent does not have suï¬cient balance (i.e., the transaction overdrafts), the transaction is marked as bad.

Additionally, any transaction which references a bad transaction in its dependency set (meaning a bad transaction is

included in the set tx.deps) is also marked as bad. The punishment for a bad transaction is that the transaction fee is

transferred from the balance of the initiating agent to the balance of each other agent, but the payment speciï¬ed by

the transaction is not transferred from the initiator to the recipient. In other words, the fee is charged as a punishment

but the transaction itself does not occur. If an agent decides that a transaction is not bad, then they reduce the balance

of the initiator and add the transaction to the recipientâs incoming payment buï¬er via the Commit function.

5.3 Transaction Fees and Balance Updates

For each transaction executed in Hearsay, the initiator of the transaction must pay a ï¬xed fee ð to each agent in the

system in return for executing the transaction. As we describe in Section 6, this fee is the main incentive by which

rational agents are encouraged to follow the Hearsay protocol. Due to the asynchronicity of communications in the

system, the order in which payments and fees are credited to agent balances must be strictly deï¬ned in order to ensure

that any two agents executing the same transaction are able to agree on the balance of that transactionâs initiator.

When a correct agent ð executes a transaction, ð deducts ð ð directly from the balance of the initiator of the trans-

action. However, rather than immediately incrementing the balance of every agent in the system by ð, ð instead adds

a fee credit to a fee buï¬er for each agent (including ð itself). In order for ð to convert their fee credits into a spendable

balance, ð must signal a fee conversion to occur with the next transaction they initiate. Speciï¬cally, ð must reference

a set of recent transactions for which ð has received a fee credit within their next transaction ð¡ð¥. This signals to each

executing agent to treat all fees referenced by ð¡ð¥ as dependencies which must be executed prior to ð¡ð¥. Then, upon

execution of ð¡ð¥, each of the fee credits referenced is converted into balance for ð.

Incoming payments to ð are treated similarly to fees. If ð is the recipient of a transaction, each agent executing the

transaction adds the transaction value to the incoming payment buï¬er for ð instead of immediately adding it to ðâs

balance. Each time ð initiates a transaction ð¡ð¥, they reference the set of incoming payments they have received since

their last outgoing transaction. These are also treated as dependencies which must be executed prior to ð¡ð¥, and the

balance of each incoming payment referenced is added to ðâs balance upon execution of ð¡ð¥.

9

Yanni Georghiades, Robert Streit, and Vijay Garg

Algorithm 1: Hearsay

Local variables : ð :: the number of agents in the system
ð :: the transaction fee
ð â {1, . . . , ð } :: my agent number
ð¹ = { }ð :: set of ð fee buï¬ers
ð = { }ð :: set of ð incoming payment buï¬ers
ðµ â Rð :: agent balances, initially all greater than ð ð and agreed upon by all agents
ð = 0ð :: agent sequence numbers, initially 0
ctr = 1 :: internal transaction counter, initially 1

1 Pay(Recipient ð , Amount ð¥ , Fee Conversion Flag ð ):
2
3

if ðµ [ð ] < ð¥ + ð ð then

exit
if f = true then

4
5

6

7
8

9

10

11

12

fees â ð¹ [ð ]
ð¹ [ð ] â { }

else

fees â { }

(tx.initiator, tx.recipient, tx.value, tx.seq, tx.deps, tx.fees) â (ð, ð, ð¥, ctr, ð [ð ], fees)
ð [ð ] â { }
ctr â ctr + 1
RRB(tx)

13
14 On RRB-Deliver(tx):
15

add tx to execution buï¬er

16
17 Condition 1: ð[tx.initiator] = tx.seq - 1
18 Condition 2: âð¡ â tx.deps âª tx.fees: ð¡ executed
19 Condition 3: (ðµ [tx.initiator] > ð ð) â¨ ( |tx.fees | > ð )
20 for transaction satisfying Conditions 1 and 2 Execute(tx):
21

tx.bad â false

22

23
24
25

26

27

28
29
30

31

32

33
34

35

36
37

38

39

40
41

42

43

for ð¡ â tx.deps do

if ð¡ â ð [tx.initiator] then

ðµ [tx.initiator] â ðµ [tx.initiator] + t.value
remove t from Q[tx.initiator]

for ð¡ â tx.fees do

if ð¡ â ð¹ [tx.initiator] then

ðµ [tx.initiator] â ðµ [tx.initiator] + ð
remove t from F[tx.initiator]

if (ðµ[tx.initiator] < ð¥ + ð ð) â¨ (âð¡ â tx.deps : t.bad = true ) then

tx.bad â true

if tx.bad = false then

Commit(tx)

ðµ[tx.initiator] â ðµ[tx.initiator] âð ð
for ð â {1, . . . , ð } do

ð¹ [ ð ] â ð¹ [ ð ] âª ð¡ð¥

ð[tx.initiator] â ð[tx.initiator] +1

(fees occur whether or not the transaction is bad)

44
45 Commit(tx):
46

ðµ[tx.initiator] â ðµ[tx.initiator] - tx.value
ð [tx.recipient] â ð [tx.recipient] âª tx

47

If fees and incoming payments were added immediately to the recipientâs balance, then two agents which have

executed diï¬erent sets of transactions which are not dependencies of ð¡ð¥ might have added diï¬erent fees and payments

to ðâs balance prior to executing ð¡ð¥. As a result, these two agents might disagree on whether or not to commit ð¡ð¥,

breaking the agreement property.

We also remark that in general, a transaction which signals a fee conversion is executed more slowly than one which

does not, as a fee conversion adds many additional dependencies which must be executed prior to the transaction. For

10

Who Needs Consensus? A Distributed Monetary System Between Rational Agents via Hearsay

this reason, fee conversions should be treated as rare events. Although an agent may choose to signal a fee conversion

at any time, it makes sense for a rational agent to wait until they need the balance for a future transaction or they

know that they will not need to initiate any transactions in the near future.

5.4 Protocol Properties

Let Hearsay be the protocol characterized by the pseudo-code in Algorithm 1. In this section we show that Hearsay
satisï¬es the following properties. Let the set of rational agents be R.

Validity. If a rational agent ð broadcasts a transaction tx, then ð eventually executes tx.

Formally. For transaction tx:

Agreement. If a rational agent ð executes a transaction tx, then all rational agents eventually execute tx. Moreover, if

âð â R, ð broadcasts ð¡ð¥ â ð executes ð¡ð¥

(1)

ð commits ð¡ð¥, then all rational agents commit ð¡ð¥.

Formally. For a transaction tx:

(cid:0)(âð â R : ð executes ð¡ð¥) â (âð â R, ð executes ð¡ð¥)(cid:1)

â§(cid:0)(âð â R : commits ð¡ð¥) â (âð â R, ð commits ð¡ð¥)(cid:1)

(2)

Integrity. For any initiator ð and sequence number ð , any rational agent executes at most one transaction with initia-

tor ð and sequence number ð .

Formally. Let ð¡ð¥1, ð¡ð¥2 be any two transactions.

(âð â R : ð executes ð¡ð¥1 â§ ð executes ð¡ð¥2) â (ð¡ð¥1.initiator â  ð¡ð¥2.initiator â¨ ð¡ð¥1.seq â  ð¡ð¥2.seq)

(3)

In order to characterize agent behavior in a setting where a rational agent may choose to deviate from Hearsay at

any time, we introduce the notion of past-correctness. However, for the sake of clarity, we simply call an correct rather

than past-correct.

Definition 5.1 (Past-correct). An agent ð is said to be past-correct at an event ð iï¬ at all local events before and

including ð, ð has acted according to Hearsay exactly.

We now introduce the ï¬rst major theorem of the paper, which states that Hearsay satisï¬es the properties of Validity,

Agreement, and Integrity if all rational agents behave correctly. In Section 6, we introduce the other major theorem of

the paper, which states that all rational agents behave correctly.

Theorem 5.2. Hearsay satisï¬es the properties of Validity, Agreement, and Integrity if no rational agent deviates from

the protocol speciï¬cation.

The intuition behind the Theorem is that, if we assume that rational agents behave correctly, if a rational agent broad-

casts a transaction then eventually all rational agents execute it and update their balances in precisely the same way.

11

Yanni Georghiades, Robert Streit, and Vijay Garg

We prove Theorem 5.2 by proving the next three lemmas. We defer the formal proofs of each lemma to Appendix B

and provide more intuitive proof sketches in this section.

Lemma 5.3. Hearsay satisï¬es Validity if no rational agent deviates from the protocol speciï¬cation.

Proof Sketch. We ï¬rst state that if a rational (and therefore correct) agent ð has executed all of their own trans-

actions prior to ð¡ð¥, and ð broadcasts a transaction tx, then ð will eventually deliver tx. We prove this statement with

the following logic. By the Validity of RRB, if ð broadcasts ð¡ð¥, then ð delivers ð¡ð¥. By hypothesis, ð has executed all

of their transactions prior to ð¡ð¥ (satisfying Condition 1). By the Hearsay speciï¬cation, if ð broadcasts ð¡ð¥, then they

must necessarily have executed all transactions that they placed in tx.deps (satisfying Condition 2). And again by the

Hearsay speciï¬cation, if ð broadcasts ð¡ð¥, their balance must be greater than ð ð (satisfying Condition 3).

The proof of the lemma then follows by simple induction. Before ð has broadcast their ï¬rst transaction ð¡ð¥, it trivially

holds that ð has delivered all of their own transactions prior to ð¡ð¥. We then use induction to show that ð will also execute
(cid:3)

each transaction that they broadcast after ð¡ð¥.

Lemma 5.4. Hearsay satisï¬es Agreement if no rational agent deviates from the protocol speciï¬cation.

Proof Sketch. We ï¬rst deï¬ne the set Î¦(ð¡ð¥), which is constructed recursively on a transaction ð¡ð¥ with initiator ð
to include ð¡ð¥, all transactions initiated by ð with sequence number less than or equal to ð¡ð¥, and any dependency of any
transaction in Î¦(ð¡ð¥). Intuitively, if a correct agent ð executes ð¡ð¥ then Î¦(ð¡ð¥) is the set of all transactions that ð must
also have executed. We also deï¬ne the height of ð¡ð¥ to be the length of the longest chain of transactions in the set Î¦(ð¡ð¥).
Intuitively, the height of ð¡ð¥ is the longest chain of dependencies a correct agent must execute prior to ð¡ð¥.

The proof uses an induction argument over transaction heights. It is clear that any transaction of height 1 has no

dependencies and the initiator must have suï¬cient balance to cover the fees, so the transaction is executed immediately

after it is delivered by each rational agent and all rational agents agree on whether or not to commit it. This forms the

base case for induction. As an induction hypothesis, we assume that all transactions up to height ð have been executed

by all rational agents and that all rational agents agree upon whether not to commit them. The induction hypothesis
implies that for some transaction ð¡ð¥ of height ð + 1, all transactions in Î¦(ð¡ð¥) other than ð¡ð¥ must have been executed by
all rational agents and that all rational agents have agreed upon whether not to commit them. We combine this with

the observation that the balance of the initiator of ð¡ð¥ can only be changed prior to the execution of ð¡ð¥ by a transaction
in Î¦(ð¡ð¥). This implies that all rational agents must have performed the same updates to the balance of tx.initiator
prior to the execution of ð¡ð¥, and therefore all rational agents agree on the balance. Finally, during the execution of

ð¡ð¥, all rational agents are guaranteed to perform the same balance updates prior to the balance check because they

are guaranteed to have executed all dependencies of ð¡ð¥ by the induction hypothesis. This necessarily means that all

rational agents execute ð¡ð¥ and agree upon whether or not to commit it, completing the proof.

The intuition behind the proof is that if some rational agent executes ð¡ð¥, they must also have executed all transactions
in Î¦(ð¡ð¥). Then for any other rational agent which has not yet executed ð¡ð¥, there must be at least one transaction in
Î¦(ð¡ð¥) that they can execute. Moreover, because the balance of any agent ð only changes during a transaction that
they initiate, the order in which transactions not initiated by ð are executed does not aï¬ect the balance checks for ðâs

transactions. As a result, all rational agents execute the same transactions and agree upon whether or not to commit
(cid:3)

each executed transaction.

Lemma 5.5. Hearsay satisï¬es Integrity if no rational agent deviates from the protocol speciï¬cation.

12

Who Needs Consensus? A Distributed Monetary System Between Rational Agents via Hearsay

Proof Sketch. The proof of this lemma follows almost directly from the Integrity of RRB. If a rational agent ð

executes two transactions with the same initiator and sequence number, it must also be true that ð delivered both

transactions. However, by the Integrity of RRB, ð will not deliver two diï¬erent transactions with the same initiator
(cid:3)

and sequence number.

It is clear that the proofs of Lemmas 5.3, 5.4, and 5.5 constitute a proof of Theorem 5.2.

5.5 Implications of Theorem 5.2

Theorem 5.2 states that if no rational agent deviates from the protocol, Hearsay satisï¬es Validity, Agreement, and In-

tegrity. These properties guarantee that Hearsay maintains the necessary functionality for a distributed money transfer

system. Speciï¬cally, Theorem 5.2 has the following corollaries.

Corollary 5.6. Any transaction broadcast by a rational agent is eventually executed by all rational agents.

This statement follows directly from the combination of Validity and Agreement and guarantees that rational agents

are able to spend their money. Without this property, the arguments used in Section 6 do not hold, as rational agents

do not beneï¬t from receiving money that they are unable to spend. However, note that this property need not hold

for Byzantine agents which broadcast conï¬icting transactions with the same sequence number. In this case, it may be

that neither transaction is ever executed.

On the other hand, agents should also not be able to spend money that they do not own and double-spends should

be impossible. If an agent could reliably spend more money than they had, this too would break down the arguments

in Section 6, as rational agents have a lower incentive to execute the protocol in order to acquire money.

Corollary 5.7. No agent may spend money they do not have or enter into debt. Moreover, no agent may spend the

same money twice.

This corollary follows from Agreement and Integrity. By Agreement, if there is any rational agent which determines

that the initiator of a transaction does not have suï¬cient balance to complete the payment, then no rational agent

commits the transaction. If the initiator does not have suï¬cient balance to cover the transaction fees, then no rational

agent even executes the transaction, again ensuring that no agent may enter a negative balance. By Integrity, if no

rational agent may execute two transactions from the same initiator with the same sequence number. This implies

that each time transaction is executed, the money is deducted from the initiatorâs balance prior to the execution of

their next transaction.

6 INCENTIVE ANALYSIS

Because we are interested in systems with a large number of rational agents, we cannot simply prove the Hearsay
protocol is correct when at least 2
3 of the agents behave correctly. We must instead show that the rational agents
achieve the maximum possible reward by following the protocol correctly. If this is the case, then rational agents will

see no reason to deviate. In particular, in this section we show that following the Hearsay protocol is a Nash equilibrium

amongst the rational agents. This is stated in the following theorem.

Theorem 6.1. No rational agent has any incentive to deviate from Hearsay, assuming the other rational agents are

following the protocol.

13

Yanni Georghiades, Robert Streit, and Vijay Garg

We prove this statement through the following two lemmas. The ï¬rst lemma states that no rational agent has

incentive to deviate from the prescribed Pay function, and the second states that no rational agent has incentive to

execute transactions incorrectly. The theorem is corollary of these two lemmas. We periodically reference the line

numbers of Algorithm 1.

Lemma 6.2. No rational agent has any incentive to deviate from the Pay function in Hearsay, assuming the other

rational agents are following the protocol.

Proof. Suppose ð is a rational agent executing the Pay function in Algorithm 1, as they wish to send a payment to

another agent or convert their fees into their balance. Note that ð will initiate this transaction as it is safe to assume ð

prefers creating a transaction over not creating it so long as the system chooses a suitable transaction fee. First see that

ð will not choose to initiate a transaction if their balance is not suï¬cient (line 2), and Condition 3 for their transaction

is therefore satisï¬ed (line 19). If ð were to do so, the other rational agents would mark the transaction as âbadâ, thereby

not carrying out the transaction yet still collecting the fee from ð anyways (lines 33-41). For the same reason, ð will

ensure that they construct their transaction correctly (lines 4-9). In particular, it is clear to see that ð will not use a

âbadâ transaction in their dependency list due to fee collection and will specify the correct recipient so as to not risk

sending funds to the wrong destination. Additionally, ð will maintain the correct sequence number and dependencies

to ensure that other rational agents are able execute the transaction according to Conditions 1 and 2 (lines 17 and 18).

Next, it is clear that ð will clear their transaction buï¬er (line 10), because theyâd prefer not to participate in unnecessary

communication. And ï¬nally ð must participate in a RRB broadcast to communicate their transaction to the other agents,

as other rational agents who are assumed to behave correctly will not execute a transaction until it is delivered in RRB.
(cid:3)

Thus ð will not deviate in the Pay function.

Lemma 6.3. No rational agent has any incentive to execute a transaction incorrectly (or not at all) in Hearsay, assuming

the other rational agents are following the protocol.

Proof. Here we examine the eï¬ects on ð that result from ð not executing a transaction as speciï¬ed by the protocol.

As the purpose of the Execute function is to reward fees and maintain local knowledge of balances, the following

argument details the potential outcomes of deviating in the Execute function and obtaining an incorrect local view

of the balances within the system. Note, Theorem 5.2 and Lemma 5.4 tell us that the Agreement property is satisï¬ed

if no rational agent deviates from Hearsay. This means that if a correct agent executes a transaction, then all correct

agents will execute the transaction. Then ð may have a local view that is inconsistent with the other rational agents

in the system if ð does not execute the transaction correctly. It is clear that incorrectly executing a transaction in a

way that gives extra funds to themselves (i.e. making money appear out of thin air) would not beneï¬t ð. Every rational

agent maintains their own local view of ðâs balance, so if those extra funds become pivotal to a transaction ð initiates,

then each rational agent will penalize ð by deducting fees for the transaction without committing it. Furthermore an

agent will always award funds to itself correctly so that it can receive payments or rewards. This tells us two important

details:

â¢ An agent cannot gain utility through awarding itself extra funds by any means. Therefore utility can only be

gained by abstaining from execution to eradicate computational costs.

â¢ Any incorrect execution (or lack of execution) that is rational would result in ðâs local view of another agent ð

being either too high or too low

The second point provides two cases for analysis.

14

Who Needs Consensus? A Distributed Monetary System Between Rational Agents via Hearsay

Suppose that an agent ð pays ð in a transaction when ð thinks ðâs balance is too low (because ð decided it was

worthwhile to avoid executing the dependencies), but the rest of the system is assured it is not. Then in this case, ð

will mark ðâs transaction as âbad" and elect not to commit it. As a result, ð will not have knowledge of funds they have

received and lose out on the opportunity to safely spend those funds.

Now assume the case that ðâs local view of the balance of some agent ð is too high. Suppose ð is Byzantine and

sends a payment to ð that is larger than the balance ð actually has but smaller than ð believes ð has. Then ð will accept

the payment to obtain more funds while the other rational agents mark this transaction as bad and do not commit it.

So, now ð has a local view of their own balance that is higher than that of the rest of the system. This means that the

other rational agents will penalize ð by deducting fees without committing ðâs transaction if these extra funds become

pivotal.

Similar to Section 4, we can apply the assumption that agents value the beneï¬ts of the service and perceive risk of

service failure negatively. Then the nature of the above scenarios would prevent rational agents from deviating from

the protocol for the beneï¬t of saving on computational resources. Therefore in both cases, ð prefers to execute the
(cid:3)

transaction correctly.

7 DISCUSSION AND FUTURE WORK

In this work we presented Hearsay, a novel distributed monetary system that tolerates both Byzantine and rational

behavior and operates without the need for consensus. To accomplish this we proposed a new reliable broadcast prim-

itive called Rational Reliable Broadcast, an incentive-based algorithm solving a classical problem at the intersection of

game theory and distributed computation. We hope our work inspires further inquiry, and we discuss some possible

future work below.

Externalities and Stronger Game Theoretic Guarantees. In Section 4 we pointed out that Rational Reliable Broadcast

may fail if we consider attacks where rational agents can âransomâ a broadcast channel through external communica-

tion channels. Interesting dynamics arise if we allow such externalities. The presence of externalities such as collusion,

extra communication, or inter-agent relationships like spite opens the ï¬oodgates to complex strategies, so we assumed

in this preliminary work that they do not occur. However, detailed investigation of the eï¬ects of these phenomena in

our algorithms and distributed computation at large could lend interesting results. In particular, providing stronger

game theoretic guarantees for our algorithms is a direct extension of our work. For example, our model is very coarse-

grained in the sense that any agent exhibiting collusive behavior must be Byzantine. However, a stronger notion of

equilibria such as ð-resilient equilibria [1, 18], which states that no group of ð players can be âbetter oï¬â by deviating,

could be used to characterize our algorithmâs sensitivity to rational collusive behavior. In this work, we proved that

behaving correctly in Hearsay and RRB constitutes a Nash (i.e., 1-resilient) equilibrium. Furthermore, other concepts

from economics such as sequential equilibrium or trembling-hand perfect equilibriumâwhere agents are allowed to react

to observed actions or âtrembleâ and play erroneous strategies with negligible probability, respectivelyâmay be used

to further reï¬ne the robustness of distributed algorithms to rational behavior.

Optimizations of the Hearsay Protocol. In the Hearsay protocol speciï¬cation in Algorithm 1, Condition 2 enforces

transaction dependencies which create a partial order beyond simply source order on transaction executions. Enforc-

ing dependency ordering is necessary in Hearsay because all agents must be able to agree on whether or not to com-

mit a transaction. This ensures that that an agent attempting to spend more money than it has is suitably punished.

However, additional ordering restrictions cause increased transaction settlement times and inevitably result in system

15

Yanni Georghiades, Robert Streit, and Vijay Garg

slowdowns. A clear optimization possible in Hearsay is to provide an agent initiating a transaction with the option

of which dependencies to reference in the transaction. If an agent already has a balance greater than their transaction

amount plus fees, there is no compelling reason to reference any dependencies. For simplicity of presentation and

analysis we forego this optimization, and we leave it to future work to further characterize the performance tradeoï¬s

of the punishment mechanism used in Hearsay. Additionally, we remark that an optimization of this variety loosely

resembles the unspent transaction output (UTXO) model used by Bitcoin [23], in which each transaction references a

set of transaction outputs which were received but not yet spent rather than an account.

Solving Classical Distributed Computing Problems in Game Theoretic Settings. We design and make use of RRB in

a black-box fashion in Hearsay in part because we believe that RRB may be useful in applications outside of money

transfer. Distributed peer-to-peer protocols in which the decision-makers in the system are real people rather than

computer processes are rapidly growing in popularity. Applying game theoretic notions of rationality and incentive

compatibility to classical distributed computing problems is critical to understanding the interactions between rational

agents and maintaining fault tolerance when agents are self-serving. Additionally, characterizing the performance

impact of the incentive mechanisms used in RRB is an interesting avenue of future work.

REFERENCES

[1] Ittai Abraham, Lorenzo Alvisi, and Joseph Y Halpern. 2011. Distributed computing meets game theory: combining insights from two ï¬elds. Acm

Sigact News 42, 2 (2011), 69â76.

[2] Ittai Abraham, Danny Dolev, Rica Gonen, and Joe Halpern. 2006. Distributed computing meets game theory: robust mechanisms for rational secret
sharing and multiparty computation. In Proceedings of the twenty-ï¬fth annual ACM symposium on Principles of distributed computing. 53â62.
[3] Ittai Abraham, Dahlia Malkhi, Kartik Nayak, Ling Ren, and Alexander Spiegelman. 2016. Solida: A blockchain protocol based on reconï¬gurable

byzantine consensus. arXiv preprint arXiv:1612.02916 (2016).

[4] Amitanand S Aiyer, Lorenzo Alvisi, Allen Clement, Mike Dahlin, Jean-Philippe Martin, and Carl Porth. 2005. BAR fault tolerance for cooperative

services. In Proceedings of the twentieth ACM symposium on Operating systems principles. 45â58.

[5] Alex Auvolat, Davide Frey, Michel Raynal, and FranÃ§ois TaÃ¯ani. 2020. Money Transfer Made Simple. arXiv preprint arXiv:2006.12276 (2020).
[6] Bruno Biais, Christophe Bisiere, Matthieu Bouvard, and Catherine Casamatta. 2019. The blockchain folk theorem. The Review of Financial Studies

32, 5 (2019), 1662â1715.

[7] Gabriel Bracha. 1987. Asynchronous Byzantine agreement protocols. Information and Computation 75, 2 (1987), 130â143.
[8] Miles Carlsten, Harry Kalodner, S. Matthew Weinberg, and Arvind Narayanan. 2016. On the Instability of Bitcoin Without the Block Reward. In
Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security (Vienna, Austria) (CCS â16). Association for Computing
Machinery, New York, NY, USA, 154â167. https://doi.org/10.1145/2976749.2978408

[9] Miguel Castro, Barbara Liskov, et al. 1999. Practical byzantine fault tolerance. In OSDI, Vol. 99. 173â186.
[10] Daniel Collins, Rachid Guerraoui, Jovan Komatovic, Petr Kuznetsov, Matteo Monti, Matej Pavlovic, Yvonne-Anne Pignolet, Dragos-Adrian Seredin-
schi, Andrei Tonkikh, and Athanasios Xygkis. 2020. Online payments by merely broadcasting messages. In 2020 50th Annual IEEE/IFIP International
Conference on Dependable Systems and Networks (DSN). IEEE, 26â38.

[11] Cynthia Dwork and Moni Naor. 1992. Pricing via processing or combatting junk mail. In Annual international cryptology conference. Springer,

139â147.

[12] Ittay Eyal, Adem Efe Gencer, Emin GÃ¼n Sirer, and Robbert Van Renesse. 2016. Bitcoin-ng: A scalable blockchain protocol. In 13th {USENIX}

symposium on networked systems design and implementation ({NSDI} 16). 45â59.

[13] Ittay Eyal and Emin GÃ¼n Sirer. 2014. Majority is not enough: Bitcoin mining is vulnerable. In International conference on ï¬nancial cryptography

and data security. Springer, 436â454.

[14] Michael J Fischer, Nancy A Lynch, and Michael S Paterson. 1985. Impossibility of distributed consensus with one faulty process. Journal of the

ACM (JACM) 32, 2 (1985), 374â382.

[15] Rachid Guerraoui, Petr Kuznetsov, Matteo Monti, Matej PavloviÄ, and Dragos-Adrian Seredinschi. 2019. The consensus number of a cryptocurrency.

In Proceedings of the 2019 ACM Symposium on Principles of Distributed Computing. 307â316.

[16] Vassos Hadzilacos and Sam Toueg. 1994. A Modular Approach to Fault-Tolerant Broadcasts and Related Problems. Technical Report. USA.
[17] Joseph Halpern and Vanessa Teague. 2004. Rational secret sharing and multiparty computation. In Proceedings of the thirty-sixth annual ACM

symposium on Theory of computing. 623â632.

16

Who Needs Consensus? A Distributed Monetary System Between Rational Agents via Hearsay

[18] Joseph Y Halpern. 2008. Beyond nash equilibrium: Solution concepts for the 21st century. In Proceedings of the twenty-seventh ACM symposium on

Principles of distributed computing. 1â10.

[19] Maurice Herlihy. 1991. Wait-free synchronization. ACM Transactions on Programming Languages and Systems (TOPLAS) 13, 1 (1991), 124â149.
[20] Yoad Lewenberg, Yoram Bachrach, Yonatan Sompolinsky, Aviv Zohar, and Jeï¬rey S. Rosenschein. 2015. Bitcoin Mining Pools: A Cooperative Game
Theoretic Analysis. In Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems (Istanbul, Turkey) (AAMAS
â15). International Foundation for Autonomous Agents and Multiagent Systems, Richland, SC, 919â927.

[21] Yoad Lewenberg, Yonatan Sompolinsky, and Aviv Zohar. 2015. Inclusive block chain protocols. In International Conference on Financial Cryptography

and Data Security. Springer, 528â547.

[22] Dahlia Malkhi and Michael Reiter. 1997. A high-throughput secure reliable multicast protocol. Journal of Computer Security 5, 2 (1997), 113â127.
[23] Satoshi Nakamoto. 2008. Bitcoin: A peer-to-peer electronic cash system. Technical Report.
[24] Rafael Pass, Lior Seeman, and Abhi Shelat. 2016. Analysis of the blockchain protocol in asynchronous networks. In Lecture Notes in
Computer Science (including subseries Lecture Notes in Artiï¬cial Intelligence and Lecture Notes in Bioinformatics), Vol. 10211 LNCS. 643â673.
https://doi.org/10.1007/978-3-319-56614-6_22

[25] Rafael Pass and Elaine Shi. 2017. Hybrid consensus: Eï¬cient consensus in the permissionless model. In 31st International Symposium on Distributed

Computing (DISC 2017). Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik.

[26] Jakub Sliwinski and Roger Wattenhofer. 2019. ABC: Proof-of-Stake without Consensus. arXiv preprint arXiv:1909.10926 (2019).
[27] Yonatan Sompolinsky and Aviv Zohar. 2015. Secure high-rate transaction processing in bitcoin. In International Conference on Financial Cryptog-

raphy and Data Security. Springer, 507â527.

17

A RATIONAL RELIABLE BROADCAST ALGORITHM

Algorithm 2: Rational Reliable Broadcast
Local variables : ð :: the number of agents in the system

Yanni Georghiades, Robert Streit, and Vijay Garg

ð â {1, . . . , ð } :: my agent number
ð  = 1 :: RRB instanceâs sequence number
Â®ðð, Â®ðð = 0ð :: echo and ready last sequence received vector
{ðð
{ðð
{ðð

ð=1 :: N lists of (sequence number, incoming echo message) tuples ordered by sequence number
ð=1 :: N lists of (sequence number, incoming ready message) tuples ordered by sequence number
ð=1 :: N lists of (sequence number, outgoing message) tuples ordered by sequence number

e in }ð
r in }ð
out }ð

1 func Broadcast(msg) :
2

Send tuple (initial, ðð ð, ð ) to all agents

6

7

8

9

10

11

12

13

14

15

16

20

21
22

23

24

28

35

36

37

38

39

40

41

42

43

44

45

e in) until sequence number is greater than Â®ðð

ð (so that duplicate messages for the same sequence number are ignored)

r in)

(seq, msg) â peak(ðð
while Â®ðð
ð = ð ðð â 1 do
if Â®ðð
ð = ð ðð â 1 then Â®ðð
pop(ðð
(seq, msg) â peak(ðð

ð â ð ðð

r in)

r in) until sequence number is greater than Â®ðð

ð (so that duplicate messages for the same sequence number are ignored)

3
4 func FlushInQueues() :
for 1 â¤ ð â¤ ð do
5

e in)

(seq, msg) â peak(ðð
while Â®ðð
ð â¥ ð ðð â 1 do
if Â®ðð
ð = ð ðð â 1 then Â®ðð
pop(ðð
(seq, msg) â peak(ðð

ð â ð ðð

e in)

17
18 func FlushOutQueue() :
19

for 1 â¤ ð â¤ ð do

(seq, msg) â peak(ðð
while min{Â®ðð

out)
ð } â® ð ðð do

ð, Â®ðð

send msg to ðð
pop(ðð
out)
(seq, msg) â peak(ðð

out)

25
26 func Deliver(ðð ð, ð â²) :
27

if ð  â¤ ð â² then ð  â ð â² + 1
if A message has not been delivered for sequence ð  then deliver msg

29
30 on Receive(initial, ðð ð, ð â²) from ð ð :
31

if echo message for sequence ð â² not already queued then push(ð

ð
out, (ð â², (echo, ðð ð,ð â²))) and FlushOutQueue()

32
33 on Receive(ð â {echo, ready}, ðð ð,ð â²) from ð ð :
34

ð
e in, (ð â², ðð ð))

if ð = echo then push(ð
ð
r in, (ð â², ðð ð))
else push(ð

FlushInQueues()
(cid:8)ð â (cid:2)ð (cid:3) : Â®ðð
if (cid:12)
(cid:12)
(cid:12)

ð â¥ ð â²

(cid:9)(cid:12)
(cid:12)
(cid:12)

â¥ (ð + ð¡ )/2 or (cid:12)
(cid:12)
(cid:12)

(cid:8)ð â (cid:2)ð (cid:3) : Â®ðð

ð â¥ ð â²

â¥ (ð¡ + 1) then

(cid:9)(cid:12)
(cid:12)
(cid:12)

if echo message for sequence ð â² not already queued then push(ð

ð
out, (ð â², (echo, ðð ð,ð â²)))

if ready message for sequence ð â² not already queued then push(ð

ð
out, (ð â², (ready, ðð ð, ð â²)))

if (cid:12)
(cid:12)
(cid:12)

(cid:8)ð â (cid:2)ð (cid:3) : Â®ðð

ð â¥ ð â²

(cid:9)(cid:12)
(cid:12)
(cid:12)

FlushOutQueue()

â¥ (2ð¡ + 1) then Deliver(ðð ð, ð â²)

18

Who Needs Consensus? A Distributed Monetary System Between Rational Agents via Hearsay

B DEFERRED PROOFS

Lemma B.1. Hearsay satisï¬es Validity if no rational agent deviates from the protocol speciï¬cation.

Proof. In this proof, all line numbers refer to lines in the Hearsay Algorithm. Additionally, we use the notation

ð.ð [ð] to designate the local variable held by agent ð which stores the current sequence number of agent ð.

Let R be the set of rational agents and C be the set of past-correct agents. Let ð be an arbitrary agent, then the

formal theorem statement is:

To prove this, we ï¬rst prove the following statement for any agent ð which broadcasts a transaction tx.

(R â C â§ âð â R, ð broadcasts ð¡ð¥) â ð executes ð¡ð¥

(R â C â§ âð â R, (ð broadcasts ð¡ð¥ â§ ð¡ð¥.ð ðð = ð  â§ ð.ð [ð] = ð  â 1)) â ð executes ð¡ð¥

(4)

(5)

In the following logic, note that although nearly every logical implication depends it, we omit copying the predicate

R â C on each line for the sake of readability.

R â C â§ âð â R, (ð broadcasts ð¡ð¥ â§ ð¡ð¥.ð ðð = ð  â§ ð.ð [ð] = ð  â 1)

=â âð â R, (ð delivers ð¡ð¥ â§ ð¡ð¥.ð ðð = ð  â§ ð.ð [ð] = ð  â 1)

(hypothesis)

(RRB validity)

=â âð â R, (ð delivers ð¡ð¥ â§ (âð¡ â tx.deps âª tx.fees, ð executes ð¡) â§ ð¡ð¥.ð ðð = ð  â§ ð.ð [ð] = ð  â 1)

(lines 9, 10, 41, 47)

=â âð â R, (ð delivers ð¡ð¥ â§ (âð¡ â tx.deps âª tx.fees, ð executes ð¡)

â§ ð¡ð¥.ð ðð = ð  â§ ð.ð [ð] = ð  â 1 â§ ð.ðµ [ð] â¥ ð ð)

=â ð executes ð¡ð¥

(line 2)

(lines 15, 17, 18, 19)

Then let ð¡ð¥1, . . . , ð¡ð¥ð be the set of all transactions broadcast by ð, in order of increasing sequence number. By lines

9 and 11, it is clear that ð¡ð¥ð .ð ðð = ð. The inductive argument is then clear.

Next we prove the base case of the induction argument.

R â C â§ ð â R â§ ð broadcasts ð¡ð¥ â§ tx.seq = 1 â ð executes ð¡ð¥

(6)

R â C â§ ð â R â§ ð broadcasts ð¡ð¥ â§ tx.seq = 1

(induction hypothesis)

=â ð â R â§ ð broadcasts ð¡ð¥ â§ tx.seq = 1 â§ ð.ð [ð] = 0

(initial condition)

=â ð executes ð¡ð¥

(Equation 5)

Next, we assume that the following holds for all transaction sequence numbers tx.seq â¤ ð.

R â C â§ ð â R â§ ð broadcasts ð¡ð¥ â§ tx.seq â¤ ð â ð executes ð¡ð¥

(7)

And then we prove that the following holds for tx.seq = ð + 1.

19

Yanni Georghiades, Robert Streit, and Vijay Garg

R â C â§ ð â R â§ ð broadcasts ð¡ð¥ â§ tx.seq = ð + 1 â ð executes ð¡ð¥

(8)

R â C â§ ð â R â§ ð broadcasts ð¡ð¥ â§ tx.seq = ð + 1

=â ð â R â§ ð broadcasts ð¡ð¥ â§ tx.seq = ð + 1 â§ ð.ð [ð] = ð

=â ð executes ð¡ð¥

(hypothesis)

(Equation 7)

(Equation 5)

(cid:3)

Lemma B.2. Hearsay satisï¬es Agreement if no rational agent deviates from the protocol speciï¬cation.

Proof. The formal statement is

(R â C â§ âð â R : ð executes ð¡ð¥) â (âð â R, ð executes ð¡ð¥ â§ (ð commits ð¡ð¥ â ð commits ð¡ð¥))

(9)

For simplicity of notation and understanding, the predicates and implications used in this proof need not hold at all

points in time, as the network is asynchronous and events are only partially ordered. Instead, the logical implications in

this proof must eventually hold. For example, if all agents except for one have executed a transaction, it may be the case

that the ï¬nal agent has not yet executed the transaction but is guaranteed to do so in the future. Additionally, when

equality is stated between local variables from two diï¬erent agents, it means only that at the moment the variables are

accessed by each agent in the context of the surrounding logic, they are guaranteed to contain the same value. Also
note that although nearly every logical implication depends it, we omit copying the predicate R â C on each line for

the sake of readability.

We deï¬ne the following sets and quantities to be used in the proof below.

Let ð be some rational agent which executes a transaction ð¡ð¥. Assume that the total number of transactions initiated

is ï¬nite. Let Î¦(ð¡ð¥) be a set of transactions deï¬ned recursively as follows:

ð¡ â Î¦(ð¡ð¥) ââ (ð¡ = ð¡ð¥) â¨ (âð£ â Î¦(ð¡ð¥) : (ð¡ â v.deps) â¨ (ð¡ â v.fees) â¨ (t.initiator = v.initiator â§ t.seq â¤ v.seq))

(10)

In other words, Î¦(ð¡ð¥) is the set of all transactions that a correct agent must execute prior to executing ð¡ð¥. It is clear

that for any ð¡ð¥,

Additionally, let â(ð¡ð¥) â N be the height of ð¡ð¥, where height is deï¬ned as

âð¡ â Î¦(ð¡ð¥) \ ð¡ð¥, Î¦(ð¡) ( Î¦(ð¡ð¥)

â(ð¡ð¥) =

1

if Î¦(ð¡ð¥) = {ð¡ð¥ }

1 + max

ð¡ âÎ¦(ð¡ð¥)\ð¡ð¥

â(ð¡),

otherwise.

ï£±ï£´ï£´ï£´ï£²
ï£´ï£´ï£´
ï£³

Intuitively, the height of ð¡ð¥ is the length of the longest chain of transaction which a correct agent must execute prior

to ð¡ð¥.

20

(11)

(12)

Who Needs Consensus? A Distributed Monetary System Between Rational Agents via Hearsay

Let ð.Î(ð¡ð¥) â Rð be the change in agent ðâs local view of the balances of each other agent which is caused by ð
executing ð¡ð¥. It is clear from the Pay function that a correct agent ð will only modify the balance of tx.initiator for any

transaction ð¡ð¥ that ð executes. More speciï¬cally,

We use the following helper statement.

âð : ( ð â  tx.initiator), ð.Î(ð¡ð¥)[ ð] = 0

(13)

R â C â§ (cid:0)(âð â R, âð â R, âð¡ â Î¦(ð¡ð¥) \ ð¡ð¥, (ð executes ð¡ð¥) â§ (ð executes ð¡) â§ (ð commits ð¡ â ð commits ð¡))
â (ð executes ð¡ð¥ â§ (ð commits ð¡ð¥ â ð commits ð¡ð¥))(cid:1)

(14)

This helper statement states that if some rational agent ð executes ð¡ð¥, all rational agents execute all dependencies of

ð¡ð¥, and all rational agents agree on whether or not to commit each dependency of ð¡ð¥, then all rational agents execute

ð¡ð¥ and agree on whether or not to commit ð¡ð¥. We prove the helper statement with the following logic.

R â Câ§(âð â R, âð â R, âð¡ â Î¦(ð¡ð¥) \ ð¡ð¥, (ð executes ð¡ð¥) â§ (ð executes ð¡) â§ (ð commits ð¡ â ð commits ð¡))

(hypothesis)

=â âð â R, âð â R, âð¡ â Î¦(ð¡ð¥) \ ð¡ð¥, (ð delivers ð¡ð¥) â§ (ð executes ð¡) â§ (ð commits ð¡ â ð commits ð¡)

(line 15)

=â âð â R, âð â R, âð¡ â Î¦(ð¡ð¥) \ ð¡ð¥, (ð delivers ð¡ð¥) â§ (ð executes ð¡) â§ (ð commits ð¡ â ð commits ð¡)

(RRB Agreement)

=â âð â R, âð â R, âð¡ â Î¦(ð¡ð¥) \ ð¡ð¥, (ð delivers ð¡ð¥) â§ (ð executes ð¡) â§ (ð commits ð¡ â ð commits ð¡)

(lines 25, 30, 39, 46;

â§ (ð.Î(ð¡) = ð.Î(ð¡))

=â âð â R, âð â R, âð¡ â Î¦(ð¡ð¥) \ ð¡ð¥, (ð delivers ð¡ð¥) â§ (ð executes ð¡) â§ (ð commits ð¡ â ð commits ð¡)

â§ (ð.ðµ [tx.initiator] = ð.ðµ [tx.initiator])

=â ð executes ð¡ð¥ â§ (ð commits ð¡ð¥ â ð commits ð¡ð¥)

Next we state the base case of our induction argument.

Equation 13)

(deï¬nition of Î(ð¡ð¥))

(lines 17, 18, 19, 23â34)

(R â C â§ âð â R : ð executes ð¡ð¥ â§â(ð¡ð¥) = 1) â (âð â R, ð executes ð¡ð¥ â§ (ð commits ð¡ð¥ â ð commits ð¡ð¥)) (15)

The proof of the base case uses the following logic.

R â Câ§âð â R : ð executes ð¡ð¥ â§ â(ð¡ð¥) = 1

=â âð â R : ð executes ð¡ð¥ â§ (Î¦(ð¡ð¥) \ ð¡ð¥ = â)

(hypothesis)

(Deï¬nition of â(ð¡ð¥))

=â âð â R, ð executes ð¡ð¥ â§ (ð commits ð¡ð¥ â ð commits ð¡ð¥)

(Equation 14)

To complete the argument, we assume that the following statement holds for all ð¡ð¥ and for any â(ð¡ð¥) â¤ ð:

(R â C â§ âð â R : ð executes ð¡ð¥ â§â(ð¡ð¥) â¤ ð) â (âð â R, ð executes ð¡ð¥ â§ (ð commits ð¡ð¥ â ð commits ð¡ð¥)) (16)

And then we perform induction over â(ð¡ð¥):

21

Yanni Georghiades, Robert Streit, and Vijay Garg

(R â C â§ âð â R : ð executes ð¡ð¥ â§ â(ð¡ð¥) = ð + 1) â (âð â R, ð executes ð¡ð¥ â§ (ð commits ð¡ð¥ â ð commits ð¡ð¥))
(17)

The proof of the inductive argument uses the following logic.

R â Câ§âð â R : ð executes ð¡ð¥ â§ â(ð¡ð¥) = ð + 1

=â âð â R : ð executes ð¡ð¥ â§ (âð â R, âð¡ â Î¦(ð¡ð¥) \ ð¡ð¥ : â(ð¡) â¤ ð,

ð executes ð¡ â§ (ð commits ð¡ â ð commits ð¡))

=â ð executes ð¡ð¥ â§ (ð commits ð¡ð¥ â ð commits ð¡ð¥)

(hypothesis)

(Equation 16)

(Equation 14)

Lemma B.3. Hearsay satisï¬es Integrity if no rational agent deviates from the protocol speciï¬cation.

Formal Proof. Let ð¡ð¥1 and ð¡ð¥2 be any two transactions.
Formally, the lemma states:

R â C â§ (âð â R, ð executes ð¡ð¥1 â§ ð executes ð¡ð¥2)
â (ð¡ð¥1.ðððð¡ððð¡ðð â  ð¡ð¥2.ðððð¡ððð¡ðð â¨ ð¡ð¥1.ð ðð â  ð¡ð¥2.ð ðð)

(cid:3)

(18)

We prove this with the following logic. Let ð be an arbitrary agent and let ð¡ð¥1, ð¡ð¥2 be two arbitrary transactions.

R â C â§ ð â R â§ ð executes ð¡ð¥1 â§ ð executes ð¡ð¥2
=â ð â R â§ ð delivers ð¡ð¥1 â§ ð delivers ð¡ð¥2
=â ð¡ð¥1.ðððð¡ððð¡ðð â  ð¡ð¥2.ðððð¡ððð¡ðð â¨ ð¡ð¥1.ð ðð â  ð¡ð¥2.ð ðð

(hypothesis)

(line 15)

(RRB Integrity)

(cid:3)

22

