{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import textstat\n",
    "import pandas as pd\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize sentiment analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to calculate Lexical Diversity\n",
    "def calculate_lexical_diversity(text):\n",
    "    words = word_tokenize(text)\n",
    "    return len(set(words)) / len(words)\n",
    "\n",
    "# Function to perform Sentiment Analysis\n",
    "def calculate_sentiment(text):\n",
    "    return sia.polarity_scores(text)\n",
    "\n",
    "# Function to calculate Readability Scores using textstat\n",
    "def calculate_readability_scores(text):\n",
    "    return textstat.flesch_kincaid_grade(text)\n",
    "\n",
    "# Function to analyze Sentence Length and Structure\n",
    "def analyze_sentence_structure(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    lengths = [len(word_tokenize(sent)) for sent in sentences]\n",
    "    avg_length = sum(lengths) / len(sentences)\n",
    "    return avg_length, lengths\n",
    "\n",
    "# Main function to process files and calculate metrics\n",
    "def process_files_and_calculate_metrics(folder, num_files):\n",
    "    results = []\n",
    "\n",
    "    files = sorted(glob.glob(os.path.join(folder, \"*.txt\")))\n",
    "\n",
    "    for i in range(min(num_files, len(files))):\n",
    "        file = files[i]\n",
    "\n",
    "        with open(file, 'r') as f:\n",
    "            text = f.read()\n",
    "\n",
    "        readability_score = calculate_readability_scores(text)\n",
    "        sentence_length_avg, sentence_lengths = analyze_sentence_structure(text)\n",
    "        lexical_diversity = calculate_lexical_diversity(text)\n",
    "        sentiment = calculate_sentiment(text)\n",
    "\n",
    "        results.append({\n",
    "            \"file\": os.path.basename(file),\n",
    "            \"readability_score\": readability_score,\n",
    "            \"sentence_length_avg\": sentence_length_avg,\n",
    "            \"lexical_diversity\": lexical_diversity,\n",
    "            \"sentiment_positive\": sentiment['pos'],\n",
    "            \"sentiment_neutral\": sentiment['neu'],\n",
    "            \"sentiment_negative\": sentiment['neg'],\n",
    "            \"sentiment_compound\": sentiment['compound']\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "# Define folders and number of files to process\n",
    "folders = [\n",
    "    'Written Blog Posts/3.5T Blog',\n",
    "    'Written Blog Posts/4o Blog Raw Text',\n",
    "    'Written Blog Posts/4o Blog',\n",
    "    'summaries'\n",
    "]\n",
    "num_files = 100  # Set the number of files to process per folder\n",
    "\n",
    "# Process each folder and save results\n",
    "for folder in folders:\n",
    "    results_df = process_files_and_calculate_metrics(folder, num_files)\n",
    "    output_file = f'{folder.replace(\" \", \"_\").replace(\"/\", \"_\")}_analysis_results.csv'\n",
    "    results_df.to_csv(output_file, index=False)\n",
    "    print(f\"Results for {folder} saved to {output_file}\")\n",
    "\n",
    "# Display results for the first folder as an example\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
