# The Impact of Self-Disclosure on Empathy Towards Anthropomorphic Agents

## Introduction

In today's rapidly advancing technological world, artificial intelligence (AI) and robots are becoming more integrated into society. As we rely more on these anthropomorphic agents for various tasks, understanding the dynamics of empathy and trust between humans and these agents is crucial. This blog post delves into a study by Takahiro Tsumura and Seiji Yamada that explores how self-disclosure by agents can influence human empathy and trust. By examining the attributes of self-disclosure and the nature of the relationship between humans and agents, the study offers insights into building effective and trustworthy relationships with AI.

## The Importance of Trust and Empathy in AI

As AI continues to infiltrate different aspects of our lives, from chatbots to generative image software, the need for trustworthy and ethical AI becomes increasingly important. Trust in AI is not just about the technology performing its tasks accurately; it's also about how humans perceive and interact with these systems. A lack of trust can lead to overconfidence or distrust in AI, both of which can result in poor task performance.

The study by Tsumura and Yamada aims to identify key factors that contribute to trust and empathy towards anthropomorphic agents. By understanding these factors, we can develop strategies to repair and maintain trust in AI, ensuring its effective use in society.

## The Role of Self-Disclosure in Building Empathy

Empathy is closely related to trust, and humans have a natural tendency to empathize with artifacts, treating them as if they were human. This phenomenon is known as the media equation. However, not all humans easily accept these agents. The study explores how self-disclosure by agents can influence empathy and trust. Self-disclosure involves sharing personal information, which can make the agent appear more relatable and human-like.

Omdahl (1995) broadly classified empathy into three types:
1. **Affective Empathy**: An emotional response to another person's emotional state.
2. **Cognitive Empathy**: A cognitive understanding of another person's emotional state.
3. **Combined Empathy**: Integrates both affective and cognitive empathy.

The study investigates how different attributes of self-disclosure (opinions and attitudes, hobbies, work, money, personality, and body) and the nature of the relationship (competitive or cooperative) influence empathy and trust.

## Experimental Design

The experiment was conducted online and involved participants watching videos of an agent giving a self-introduction. The videos varied in terms of the self-disclosure attributes and the nature of the relationship with the agent. Participants then completed questionnaires to assess their trust and empathy towards the agent.

### Hypotheses

The study formulated four hypotheses:
1. Trust towards the agent changes with the attribute of self-disclosure.
2. Trust towards the agent increases when a cooperative relationship is presented rather than a competitive relationship.
3. Empathy towards the agent changes with the attribute of self-disclosure but does not change with the type of relationship presented.
4. The empathy capacity of the agent does not change with the attribute of self-disclosure, but it changes with the type of relationship presented.

### Participants

The study involved 587 participants, with a mean age of 48.90 years. Participants were compensated for their time, and the reliability of the questionnaires was confirmed using Cronbach's alpha coefficient.

### Results

The results showed that self-disclosure attributes and relationship type did not significantly impact trust towards the agent. However, empathy towards the agent was influenced by the attribute of self-disclosure. Specifically, the self-disclosure related to work elicited more empathy than self-disclosure related to money. Additionally, participants perceived agents in cooperative relationships as having greater empathy capacity than those in competitive relationships.

## Discussion

The findings suggest that while self-disclosure attributes and relationship types may not directly influence trust, they do affect empathy towards the agent. This indicates that designing AI interactions with appropriate self-disclosure attributes can enhance human empathy towards these agents. Moreover, presenting the agent as a cooperative partner can lead to a higher perceived empathy capacity, fostering a more positive relationship.

These insights are valuable for developing AI systems that are more acceptable and trustworthy to humans. By incorporating self-disclosure and emphasizing cooperative relationships, we can create more empathetic and effective AI agents.

## Conclusion

Building trust and empathy with anthropomorphic agents is vital for their successful integration into society. The study by Tsumura and Yamada highlights the importance of self-disclosure and relationship types in influencing human empathy towards AI. By understanding these factors, we can design AI interactions that foster positive and trustworthy relationships.

As AI continues to evolve, it is essential to focus on the human aspects of these interactions. By enhancing empathy and trust, we can ensure that AI systems are not only efficient and effective but also relatable and accepted by the people who use them.

## Engage with Us

What are your thoughts on the role of empathy in AI interactions? Have you ever felt a connection with an AI or robot? Share your experiences and insights in the comments below. Let's continue the conversation about building better relationships with the technology that shapes our lives.

## References

1. Takahiro Tsumura and Seiji Yamada. Changing human’s impression of empathy from agent by verbalizing agent’s position.
2. Omdahl, B. L. (1995). Cognitive appraisal, emotion, and empathy. New York: Psychology Press.
3. Preston, S. D., & de Waal, F. B. M. (2002). Empathy: Its ultimate and proximate bases. Behavioral and Brain Sciences, 25(1), 1-20.
4. Maehigashi, A., Tsumura, T., & Yamada, S. (2022). Effects of beep-sound timings on trust dynamics in human-robot interaction. In Social Robotics, Springer Nature Switzerland.
5. Okamura, K., & Yamada, S. (2020). Adaptive trust calibration for human-AI collaboration. PLOS ONE, 15(2), 1-20.