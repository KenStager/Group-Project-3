
# Blog Post Generation and Analysis Project

## Overview

This project aims to explore the capabilities of advanced machine learning models, specifically GPT-3.5-turbo and GPT-4, in generating coherent and accurate blog posts from various sources. We focused on the following objectives:

1. **Model Comparison**: Evaluate and compare the outputs of GPT-3.5-turbo (3.5T) and GPT-4 (4o) models in terms of quality, coherence, and relevance of the generated blog posts.
2. **Input Type Evaluation**: Assess the differences in blog post quality when generated from full raw texts versus summaries. This involved:
   - Generating blog posts directly from raw texts.
   - Generating blog posts from summaries of the raw texts.
3. **Content Analysis**: Analyze the generated blog posts to determine:
   - The fidelity of the generated content to the original texts.
   - The differences in writing styles and content richness between models.
   - The effectiveness of each model in generating informative and engaging blog posts.
4. **Data Source Utilization**: Utilize a robust dataset from arXiv, including both raw texts and summaries, to ensure a diverse and comprehensive evaluation.

### Project Workflow

1. **Data Collection**: Gather full raw texts and their corresponding summaries from arXiv.
2. **Blog Post Generation**: Use GPT-3.5-turbo and GPT-4 models to generate blog posts from the collected data.
3. **Analysis and Comparison**: Conduct detailed analyses and comparisons of the generated blog posts using various metrics and visualizations.
4. **Result Interpretation**: Interpret the results to draw conclusions about the performance and applicability of each model for blog post generation.

### Key Questions Addressed

- **Accuracy from Summaries**: Can blog posts generated from summaries maintain the accuracy and depth of those generated from full raw texts?
- **Model Performance**: How does the performance of GPT-3.5-turbo compare to GPT-4 in terms of content generation?
- **Content Differences**: What are the notable differences in the content, style, and information richness between blog posts generated by different models and input types?

### Findings

Our analysis revealed several insights:
- Blog posts generated from summaries can be quite accurate, but may lack some depth and detail compared to those generated from full texts.
- GPT-4 generally produced more coherent and contextually relevant blog posts than GPT-3.5-turbo.
- The differences in content generation between raw texts and summaries highlighted the strengths and limitations of each approach.

### Practical Applications

The findings of this project have practical implications for content creators, researchers, and developers who seek to leverage AI for generating written content. Understanding the capabilities and limitations of different models and input types can help in selecting the appropriate tools and methods for specific content generation tasks.

## Directory Structure

```
## Blog Analyzation DFs
- summaries_analysis_results.csv
- Written_Blog_Posts_3.5T_Blog_analysis_results.csv
- Written_Blog_Posts_4o_Blog_analysis_results.csv
- Written_Blog_Posts_4o_Blog_Raw_Text_analysis_results.csv

### Individual Comparative CSVs
- comparison_results_4o_Sum_to_4o_Raw.csv
- comparison_results_35blog_sum_to_4oblog_sum.csv
- comparison_results_raw_to_4o_sum_blog.csv
- comparison_results_raw_to_4o.csv
- comparison_results_sum_to_3.5.csv
- comparison_results_sum_to_4o_blog.csv
- comparison_results_sum_to_raw.csv

### Subdirectories
- raw_texts
- summaries
- Supporting Documents

## Written Blog Posts
- 3.5T Blog
- 4o Blog
- 4o Blog Raw Text

## Jupyter Notebooks
- 3.5S3Writer.ipynb
- 4oS3Writer.ipynb
- Comparative Eval.ipynb
- Dataframe Combiner.ipynb
- Individual Source Eval.ipynb
- S3 Downloader.ipynb
- Visualizations.ipynb

## Other Files
- average_metrics_by_comparison_type.csv
- combined_comparative_results.csv
- output.png
- README.md
```

## Detailed Descriptions

### Blog Analyzation DFs
This directory contains various CSV files that summarize the results of our blog post analysis:
- **summaries_analysis_results.csv**: Contains the analysis results of blog posts generated from summaries.
- **Written_Blog_Posts_3.5T_Blog_analysis_results.csv**: Analysis results of blog posts generated using GPT-3.5-turbo.
- **Written_Blog_Posts_4o_Blog_analysis_results.csv**: Analysis results of blog posts generated using GPT-4.
- **Written_Blog_Posts_4o_Blog_Raw_Text_analysis_results.csv**: Analysis results of blog posts generated using GPT-4 from raw texts.

### Individual Comparative CSVs
These CSV files contain detailed comparisons between different models and input types:
- **comparison_results_4o_Sum_to_4o_Raw.csv**: Comparison between GPT-4 outputs from summaries and raw texts.
- **comparison_results_35blog_sum_to_4oblog_sum.csv**: Comparison between GPT-3.5-turbo and GPT-4 outputs from summaries.
- **comparison_results_raw_to_4o_sum_blog.csv**: Comparison between raw texts and summaries generated by GPT-4.
- **comparison_results_raw_to_4o.csv**: Comparison between raw texts generated by GPT-4.
- **comparison_results_sum_to_3.5.csv**: Comparison between summaries generated by GPT-3.5-turbo.
- **comparison_results_sum_to_4o_blog.csv**: Comparison between summaries and blog posts generated by GPT-4.
- **comparison_results_sum_to_raw.csv**: Comparison between summaries and raw texts.

### Subdirectories
- **raw_texts**: Contains the raw text files pulled from arXiv.
- **summaries**: Contains the summary files pulled from arXiv.
- **Supporting Documents**: Additional documents supporting the project.

### Written Blog Posts
- **3.5T Blog**: Blog posts generated using GPT-3.5-turbo.
- **4o Blog**: Blog posts generated using GPT-4.
- **4o Blog Raw Text**: Blog posts generated using GPT-4 from raw texts.

### Jupyter Notebooks
- **3.5S3Writer.ipynb**: Jupyter Notebook for generating blog posts using GPT-3.5-turbo.
- **4oS3Writer.ipynb**: Jupyter Notebook for generating blog posts using GPT-4.
- **Comparative Eval.ipynb**: Notebook for comparing the results of different models.
- **Dataframe Combiner.ipynb**: Notebook for combining various dataframes for analysis.
- **Individual Source Eval.ipynb**: Notebook for evaluating individual sources.
- **S3 Downloader.ipynb**: Notebook for downloading data from S3.
- **Visualizations.ipynb**: Notebook for creating visualizations of the analysis results.

### Other Files
- **average_metrics_by_comparison_type.csv**: Contains average metrics for different comparison types.
- **combined_comparative_results.csv**: Combined results of all comparative analyses.
- **output.png**: Visualization output.
- **README.md**: This file.

## Data Sources

We pulled full raw texts and summaries from arXiv for use in generating blog posts. These texts were used as input data for the various machine learning models we employed in this project.

## How to Use

1. **Setting up the Environment**: Ensure you have the necessary dependencies installed. You can do this by running:
   ```sh
   pip install -r requirements.txt
   ```
2. **Generating Blog Posts**:
   - Use the `3.5S3Writer.ipynb` notebook to generate blog posts with GPT-3.5-turbo.
   - Use the `4oS3Writer.ipynb` notebook to generate blog posts with GPT-4.
3. **Analyzing Results**:
   - Use the `Comparative Eval.ipynb` notebook to compare the results from different models.
   - Use the `Visualizations.ipynb` notebook to visualize the analysis results.
4. **Combining Data**: Use the `Dataframe Combiner.ipynb` notebook to combine dataframes for a comprehensive analysis.
5. **Downloading Data**: Use the `S3 Downloader.ipynb` notebook to download necessary data from S3.

## Results and Findings

Our analysis showed that blog posts generated from summaries can be quite accurate, but there are notable differences between the outputs of GPT-3.5-turbo and GPT-4. The comparative results and visualizations provide detailed insights into these differences.

## Contributions

If you would like to contribute to this project, please fork the repository and submit a pull request. We welcome all contributions!

## License

This project is licensed under the MIT License. See the `LICENSE` file for details.

---

Feel free to reach out if you have any questions or need further assistance.

Happy coding!
